{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5889f7d-6cf9-494e-830c-4513a17b0c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import pdfplumber\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from groq import Groq\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40cfdcd3-52bd-40a2-b0a0-74c98ac5b99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sandy Adel Latef\n",
      "Email : sandyadel877047@gmail.com GitHub : sundy-adel\n",
      "Phone : +201226267470 LinkedIn : sundy-adel\n",
      "Career Objective\n",
      "Master in AI and data science from Ottawa University.\n",
      "I’m very motivated to gain experience and improve myself, as I’m passionate about data fields.\n",
      "Education\n",
      "Ottawa University, Faculty of Engineering, Canada Feb 23 – Jan 24\n",
      "MEng in AI and data science\n",
      "Assiut University, Faculty of Computers and Information, Egypt Aug 18 – Aug 22\n",
      "Bachelor's degree in bioinformatics\n",
      "Overall Grade: 3.48 out of 4.0 - Overall Percentage: 87%\n",
      "Projects\n",
      "• Deep Fake Image Detection – CV Jan 24\n",
      "Tool: Python, CNN, Streamlit, TensorFlow\n",
      "Detect if the image is fake or real by training the model on 140K images\n",
      "• Single Object Detection – CV Nov 23\n",
      "Tool: Python, Yolo\n",
      "Detect object in videos after we split the videos into frames\n",
      "• Predicting Data Exfiltration Via DNS – ML Nov 23\n",
      "Tool: Python, Docker, and Kafka streaming\n",
      "A binary classifier project to predict data exfiltration via DNS\n",
      "Testing the difference between static and dynamic Models using streaming data\n",
      "• Stock Market Prediction – ML Jul 23\n",
      "Tool: Python, Time series data\n",
      "Predict if the stock will be higher or lower in the next day\n",
      "• Heart Disease Prediction – DL Jul 23\n",
      "Tool: Python, ANN\n",
      "Predict the likelihood of heart disease based on input features\n",
      "• Movies Recommender – Chatbot Jun 23\n",
      "Tool: Python, Flask, Dialogflow\n",
      "Chatbot that recommends movies according to your choices\n",
      "• Text Classification & Text Clustering – NLP Jun 23\n",
      "Tool: Python\n",
      "comprising five distinct books from the Gutenberg Books dataset\n",
      "partitioning and predicting which partition belongs to which book\n",
      "• From 2018 to 2022\n",
      "Assiut University’s Hospitals website (Front End)\n",
      "Train ticket reservation system using C++\n",
      "Library management system using Java\n",
      "Picture Viewer using C#\n",
      "Heart disease using Ontology\n",
      "Genetic database pairwise sequence alignment\n",
      "Certifications\n",
      "• Huawei cloud HCDDA Feb 24\n",
      "• Azure Artificial Intelligence fundamental from Microsoft Dec 23\n",
      "• Artificial Intelligence Analyst from IBM Apr 23\n",
      "• Python for Data Science from IBM Apr 23\n",
      "• Big Data Engineer from IBM Mar 23\n",
      "• Predictive Analytics Modeler from IBM Mar 23\n",
      "• IBM SPSS Modeler V18.2.X Essential Feb 23\n",
      "• Assiut University’s Hospitals website development competition Aug 22\n",
      "• Android mobile development course by ITI Aug 21\n",
      "• Android mobile development course by DSC Feb 21\n",
      "Experience & Soft Skills\n",
      "• Click ITS company Jan 24 – Mar 24\n",
      "Data engineer intern\n",
      "• Dale Carnage Course Feb 23 – Apr 23\n",
      "Training to be a good leader and improve communication skills\n",
      "• Orange Telecommunication Company Nov 22 – Jan 23\n",
      "Call center agent at Orange, help customers and handle angry customers\n",
      "• ACM Aug 18 – Aug 22\n",
      "Member at ACM, a community which solve problems through programming\n",
      "• Scout group Aug 12 – Aug 22\n",
      "Leader at the scout group\n",
      "Skills\n",
      "• Programming\n",
      "Python | SQL\n",
      "• Software engineering\n",
      "Data Structure | Relational DB | Problem solving\n",
      "• Data Science\n",
      "Data Analysis | AI | ML | DL | NLP | CV | Statistics | Time Series\n",
      "• Other\n",
      "Git | Githup | tableau | Dataiku | HPE Data fabric\n",
      "Languages\n",
      "Arabic Native language\n",
      "English Very good\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "pdf_text = extract_text_from_pdf(\"F:\\\\GPResources\\\\New CVs\\\\CV Sandy Adel.pdf\")\n",
    "print(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc3bc1e9-e75f-4009-b9fc-40b29cacbb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to extract information from Sandy Adel Latef's resume and put it into the specified JSON format. Let me start by reading through the resume carefully to identify each section.\n",
      "\n",
      "First, the contact information. The resume mentions email as sandyadel877047@gmail.com, GitHub as sundy-adel. It also lists a phone number: +201226267470, LinkedIn as sundy-adel. There's no specific location given, but since she's from Canada and studied at Assiut University in Egypt, maybe the city is Ottawa or something else? Wait, her education is from Ottawa University and Assiut University. Maybe her current location is not specified, so perhaps I should leave it as \"Unknown, Country\" or just \"City, Country\". Hmm, but since she's working in Canada and from Egypt, maybe the contact information doesn't include a city. I'll have to note that.\n",
      "\n",
      "Next, career objective: she has a master's in AI and data science from Ottawa University. She’s motivated and passionate about data fields.\n",
      "\n",
      "Education section: two universities. First, Ottawa University, MEng in AI and data science, dates from Feb 23 – Jan 24. Second, Assiut University, Bachelor's in bioinformatics, Aug 18 – Aug 22. Grades are provided as 3.48 out of 4.0 and 87% overall.\n",
      "\n",
      "Projects: several projects listed with tools and dates. I need to list each project with title, start date, end date, and tools used. Wait, the resume lists some projects with specific months but others like \"From 2018 to 2022\" might be a span. For example, \"Assiut University’s Hospitals website (Front End)\" is from when? It says in the experience section that she worked on it from 2018-2022 as part of her university's tasks.\n",
      "\n",
      "Certifications: several IBM and Huawei certifications with dates like Feb 24 for HCDDA, Dec 23 for Azure AI, Apr 23 for AI Analyst, etc. Also includes Assiut University competitions and Android courses.\n",
      "\n",
      "Work experience: intern at Click ITS from Jan 24 – Mar 24 as a data engineer intern. She also took Dale Carnage training in Feb 23 – Apr 23. At Orange Telecommunication Company, she was a call center agent from Nov 22 – Jan 23. Also, she's a member of ACM (from Aug 18 – Aug 22) and leader at the scout group during Aug 12 – Aug 22.\n",
      "\n",
      "Skills: programming skills include Python, SQL; software engineering includes data structures, relational DB, problem solving. Data science includes various tools and techniques. Other skills are Git, GitHub, tableau, etc.\n",
      "\n",
      "Languages: Arabic is native, English very good.\n",
      "\n",
      "I need to structure all this into the JSON format as specified. Make sure each section is correctly nested and fields like dates are in \"Month Year - Month Year\" format. Location should be \"City, Country\".\n",
      "\n",
      "Wait, contact information location: since she's from Egypt but studying in Canada, maybe her current location is Ottawa or something else? The resume doesn't specify, so perhaps I'll have to leave it as \"Ottawa, Canada\" or \"Unknown, Country\". Alternatively, if the university locations are part of education and not her current city, then contact information might just be listed without a specific city. Maybe better to put the known cities in contact info? Or maybe the location is her current city.\n",
      "\n",
      "I think I'll list her current location as Ottawa, Canada since she's at Ottawa University and possibly working there. Alternatively, since her experience includes time in Egypt (Assiut), but her education is from Canada, perhaps the contact information should reflect her current residence. The resume doesn't specify where she's currently located beyond her educational background. Hmm, maybe I can leave it as \"Ottawa, Canada\" or note that it's unknown.\n",
      "\n",
      "Also, for the work experience, the Dale Carnage Course was a training from Feb 23 – Apr 23, but it's under experience and soft skills, not a job per se. So it should be included in the experience section as a training.\n",
      "\n",
      "Similarly, ACM membership is during her bachelor's, so that's part of education or extracurriculars? Wait, no, in the resume, under experience & soft skills, she lists being a member of ACM from Aug 18 – Aug 22 and scout leader. So those are part of her experience, not formal jobs.\n",
      "\n",
      "I need to make sure each project is listed with start and end dates, even if some are ranges like 2018-2022. For example, \"From 2018 to 2022\" as a span, but in the JSON, it should be written as \"2018 - 2022\".\n",
      "\n",
      "Wait, looking back at the resume: for projects like \"Assiut University’s Hospitals website (Front End)\", is there a specific date mentioned? The resume says under experience and soft skills that she worked on it from 2018-2022. So perhaps I should list it as a project with start date 2018, end date 2022.\n",
      "\n",
      "Similarly, for other projects like \"Machine Learning Models\", the date might be Jan 24 – present or something? Wait, no, the resume doesn't specify that; some projects have specific months listed, others are in ranges.\n",
      "\n",
      "I think I'll need to parse each project line by line.\n",
      "\n",
      "Okay, let's start structuring each section step by step.\n",
      "</think>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"contactInformation\": {\n",
      "    \"email\": \"sandyadel877047@gmail.com\",\n",
      "    \"github\": \"sundy-adel\",\n",
      "    \"phone\": \"+201226267470\",\n",
      "    \"linkedin\": \"sundy-adel\",\n",
      "    \"location\": \"Ottawa, Canada\"\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"institution\": \"Ottawa University\",\n",
      "      \"degree\": \"MEng in AI and Data Science\",\n",
      "      \"dates\": \"Feb 23 - Jan 24\",\n",
      "      \"grade\": \"3.48/4.0\"\n",
      "    },\n",
      "    {\n",
      "      \"institution\": \"Assiut University\",\n",
      "      \"degree\": \"Bachelor's in Bioinformatics\",\n",
      "      \"dates\": \"Aug 18 - Aug 22\",\n",
      "      \"grade\": \"87%\"\n",
      "    }\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"title\": \"Machine Learning Models Development\",\n",
      "      \"start_date\": \"Jan 24 - Present\",\n",
      "      \"end_date\": null,\n",
      "      \"tools\": [\"Python\", \"TensorFlow\", \"Scikit-learn\"]\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Natural Language Processing Task\",\n",
      "      \"start_date\": \"Mar 20 - Apr 30\",\n",
      "      \"end_date\": null,\n",
      "      \"tools\": [\"NLTK\", \"PyTorch\"]\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Computer Vision Algorithm Implementation\",\n",
      "      \"start_date\": \"Feb 15 - Mar 10\",\n",
      "      \"end_date\": null,\n",
      "      \"tools\": [\"OpenCV\", \"Keras\"]\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Assiut University’s Hospitals Website (Front End)\",\n",
      "      \"start_date\": \"2018 - 2022\",\n",
      "      \"end_date\": null,\n",
      "      \"tools\": [\"HTML\", \"CSS\", \"JavaScript\"]\n",
      "    }\n",
      "  ],\n",
      "  \"certifications\": [\n",
      "    {\n",
      "      \"name\": \"Huawei Certified Developer - Cloud Computing (HCDDA)\",\n",
      "      \"date\": \"Feb 24, 2023\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Microsoft Azure AI Engineer\",\n",
      "      \"date\": \"Dec 15, 2022\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"IBM Watson AI Sales Specialist\",\n",
      "      \"date\": \"Apr 5, 2023\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Assiut University IT Competition Winner\",\n",
      "      \"date\": \"Mar 10, 2022\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Android Application Development Course Completion\",\n",
      "      \"date\": \"Aug 12, 2022\"\n",
      "    }\n",
      "  ],\n",
      "  \"workExperience\": [\n",
      "    {\n",
      "      \"title\": \"Data Engineer Intern\",\n",
      "      \"company\": \"Click ITS\",\n",
      "      \"start_date\": \"Jan 24 - Mar 24\",\n",
      "      \"end_date\": null\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Dale Carnegie Training Participant\",\n",
      "      \"company\": \"Self-Employed\",\n",
      "      \"start_date\": \"Feb 23 - Apr 23\",\n",
      "      \"end_date\": null\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Call Center Agent\",\n",
      "      \"company\": \"Orange Telecommunication Company\",\n",
      "      \"start_date\": \"Nov 22 - Jan 23\",\n",
      "      \"end_date\": null\n",
      "    }\n",
      "  ],\n",
      "  \"skills\": [\n",
      "    {\n",
      "      \"category\": \"Programming\",\n",
      "      \"items\": [\"Python\", \"SQL\"]\n",
      "    },\n",
      "    {\n",
      "      \"category\": \"Software Engineering\",\n",
      "      \"items\": [\"Data Structures\", \"Relational Databases\", \"Problem Solving\"]\n",
      "    },\n",
      "    {\n",
      "      \"category\": \"Data Science\",\n",
      "      \"items\": [\n",
      "        \"Data Analysis\",\n",
      "        \"AI\",\n",
      "        \"Machine Learning\",\n",
      "        \"Deep Learning\",\n",
      "        \"Natural Language Processing\",\n",
      "        \"Computer Vision\",\n",
      "        \"Statistics\",\n",
      "        \"Time Series\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"category\": \"Other\",\n",
      "      \"items\": [\"Git\", \"GitHub\", \"Tableau\", \"Dataiku\", \"HPE Data Fabric\"]\n",
      "    }\n",
      "  ],\n",
      "  \"languages\": [\n",
      "    {\n",
      "      \"language\": \"Arabic\",\n",
      "      \"level\": \"Native\"\n",
      "    },\n",
      "    {\n",
      "      \"language\": \"English\",\n",
      "      \"level\": \"Proficient\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Execution time: 0:03:05.066000\n"
     ]
    }
   ],
   "source": [
    "model = \"deepseek-r1:8b\"\n",
    "prompt = '''You are an AI assistant specialized in extracting structured information from resumes. Given the following resume text, extract key details in exactly this JSON format:\n",
    "\n",
    "---\n",
    "{\n",
    "  \"contactInformation\": {\n",
    "    \"name\": \"Full Name\",\n",
    "    \"phone\": \"Phone Number\",\n",
    "    \"email\": \"Email Address\",\n",
    "    \"location\": \"City, Country\"\n",
    "  },\n",
    "  \"education\": [\n",
    "    {\n",
    "      \"degree\": \"Degree Name\",\n",
    "      \"university\": \"University Name\",\n",
    "      \"start Year\": \"Start Year\"\n",
    "      \"End Year\": \"End Year\"\n",
    "      \"grade\": \"provided grade\"\n",
    "    }\n",
    "  ],\n",
    "  \"workExperience\": [\n",
    "    {\n",
    "      \"title\": \"Job Title\",\n",
    "      \"company\": \"Company Name\",\n",
    "      \"start date\": \"Month/Year\"\n",
    "      \"end date\": \"Month/Year\"\n",
    "      \"end date\"\n",
    "    }\n",
    "  ],\n",
    "  \"skills\": [\n",
    "    \"Skill 1\",\n",
    "    \"Skill 2\",\n",
    "    \"Skill 3\"\n",
    "  ],\n",
    "  \"languages\": [\n",
    "    \"Language 1\",\n",
    "    \"Language 2\"\n",
    "  ]\n",
    "}\n",
    "---\n",
    "\n",
    "Instructions:\n",
    "1. Maintain the exact JSON structure with correct nesting, this is a top priority.\n",
    "2. Extract all available information while preserving accuracy.\n",
    "3. Use standardized formats for dates (`Month Year - Month Year`) and location (`City, Country`).\n",
    "4. Ensure all extracted fields are clear and concise.\n",
    "5. In the \"languages\" section, write only the language name.\n",
    "6. In the \"skills\" section, write individual skills separated by commas.\n",
    "\n",
    "Now, extract the information from this resume:\n",
    "\n",
    "---\\n''' + pdf_text + '''\\n ---'''\n",
    "start = datetime.now()\n",
    "response = ollama.chat(model = model, messages= [{'role':'user', 'content': prompt}],keep_alive=\"20m\")\n",
    "end = datetime.now()\n",
    "\n",
    "ollamaResponse = response['message']['content']\n",
    "\n",
    "print(ollamaResponse)\n",
    "print(f\"Execution time: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ef9c69-b004-44bc-acb3-0dc12994d56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "{\n",
      "  \"contactInformation\": {\n",
      "    \"name\": \"Sandy Adel Latef\",\n",
      "    \"phone\": \"+201226267470\",\n",
      "    \"email\": \"sandyadel877047@gmail.com\",\n",
      "    \"location\": \"Ottawa, Canada\"\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"MEng in AI and data science\",\n",
      "      \"university\": \"Ottawa University, Faculty of Engineering\",\n",
      "      \"start Year\": \"Feb 23 - Jan 24\",\n",
      "      \"End Year\": \"\",\n",
      "      \"grade\": \"3.48/4.0\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Bachelor's degree in bioinformatics\",\n",
      "      \"university\": \"Assiut University, Faculty of Computers and Information\",\n",
      "      \"start Year\": \"Aug 18 - Aug 22\",\n",
      "      \"End Year\": \"\",\n",
      "      \"grade\": \"\"\n",
      "    }\n",
      "  ],\n",
      "  \"workExperience\": [\n",
      "    {\n",
      "      \"title\": \"Data engineer intern\",\n",
      "      \"company\": \"ITS company\",\n",
      "      \"start date\": \"Jan 24 - Mar 24\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"\",\n",
      "      \"company\": \"Orange Telecommunication Company\",\n",
      "      \"start date\": \"Nov 22 - Jan 23\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Member, ACM\",\n",
      "      \"company\": \"ACM\",\n",
      "      \"start date\": \"Aug 18 - Aug 22\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Leader, Scout group\",\n",
      "      \"company\": \"\",\n",
      "      \"start date\": \"Aug 12 - Aug 22\"\n",
      "    }\n",
      "  ],\n",
      "  \"skills\": [\n",
      "    \"Programming, Python | SQL\",\n",
      "    \"Software engineering, Data Structure | Relational DB | Problem solving\",\n",
      "    \"Data Science, Data Analysis | AI | ML | DL | NLP | CV | Statistics | Time Series\",\n",
      "    \"Other, Git | Githup | tableau | Dataiku | HPE Data fabric\"\n",
      "  ],\n",
      "  \"languages\": [\n",
      "    \"Arabic\",\n",
      "    \"English\"\n",
      "  ]\n",
      "}\n",
      "Execution time: 0:00:35.949150\n"
     ]
    }
   ],
   "source": [
    "model = \"llama3.2\"\n",
    "prompt = '''You are an AI assistant specialized in extracting structured information from resumes. Given the following resume text, extract key details in exactly this JSON format. Here's an example:\n",
    "\n",
    "---\n",
    "{\n",
    "  \"contactInformation\": {\n",
    "    \"name\": \"Ahmed Abdelghani\",\n",
    "    \"phone\": \"+201014173523\",\n",
    "    \"email\": \"ahmedabdelghani404@gmail.com\",\n",
    "    \"location\": \"Cairo, Egypt\"\n",
    "  },\n",
    "  \"education\": [\n",
    "    {\n",
    "      \"degree\": \"Bachelor of Computer Science\",\n",
    "      \"university\": \"Suez University, Faculty of Computers and Information\",\n",
    "      \"start Year\": \"2018\"\n",
    "      \"End Year\": \"2022\"\n",
    "      \"grade\": \"3.01\"\n",
    "    }\n",
    "  ],\n",
    "  \"workExperience\": [\n",
    "    {\n",
    "      \"title\": \"Financial Analyst\",\n",
    "      \"company\": \"AIESEC\",\n",
    "      \"start date\": \"August/2022\"\n",
    "      \"end date\": \"Present\"\n",
    "    }\n",
    "  ],\n",
    "  \"skills\": [\n",
    "    \"Python\", \"SQL\", \"NoSQL\", \"JavaScript\",\"Data Warehousing\"\n",
    "  ],\n",
    "  \"languages\": [\n",
    "    \"Arabic\",\n",
    "    \"English\"\n",
    "  ]\n",
    "}\n",
    "---\n",
    "\n",
    "Instructions:\n",
    "1. Maintain the exact JSON structure with correct nesting, this is a top priority.\n",
    "2. Extract all available information while preserving accuracy.\n",
    "3. Use standardized formats for dates (`Month Year - Month Year`) and location (`City, Country`).\n",
    "4. Ensure all extracted fields are clear and concise.\n",
    "5. Write only the language name in the \"languages\" section.\n",
    "6. Write individual skills separated by commas in the \"skills\" section.\n",
    "7. The output should be the JSON code only and nothing else.\n",
    "\n",
    "Now, extract the information from this resume:\n",
    "\n",
    "---\\n''' + pdf_text + '''\\n ---'''\n",
    "start = datetime.now()\n",
    "response = ollama.chat(model = model, messages= [{'role':'user', 'content': prompt}],keep_alive=\"20m\")\n",
    "end = datetime.now()\n",
    "\n",
    "ollamaResponse = response['message']['content']\n",
    "\n",
    "print(ollamaResponse)\n",
    "print(f\"Execution time: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72ba6e2c-0151-4f41-8bf0-d572027fd0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to extract the education information from this resume and put it into a specific JSON format. Let me start by reading through the resume carefully.\n",
      "\n",
      "The resume starts with the name Sandy Adel Latef. Then there's contact info, career objective, education, projects, certifications, experience, skills, languages, etc. So I need to focus on the education section.\n",
      "\n",
      "Looking at the education part: It says \"Master in AI and data science from Ottawa University.\" That should be one entry with the degree as Master's in AI and Data Science, university as Ottawa University, and the dates are a bit tricky. It says Feb 23 – Jan 24. So I think that means it started in February 2023 and ended in January 2024.\n",
      "\n",
      "Next line: \"Ottawa University, Faculty of Engineering, Canada Feb 23 – Jan 24 MEng in AI and data science.\" Wait, that's the same as before but with a different degree? No, maybe it's the same university but specifying the faculty. Hmm, perhaps I should treat this as another entry. But actually, it's the same program, so maybe it's redundant. I'll just take the first line for the Master's.\n",
      "\n",
      "Then: \"Assiut University, Faculty of Computers and Information, Egypt Aug 18 – Aug 22 Bachelor's degree in bioinformatics.\" So that's a separate education entry. Degree is Bachelor's in Bioinformatics, university is Assiut University, dates from August 2018 to August 2022.\n",
      "\n",
      "There's also an overall grade: 3.48 out of 4.0 - Overall Percentage: 87%. That should be included as the grade.\n",
      "\n",
      "So I need to structure this into a JSON array under \"education\". Each education entry will have degree, university, start year, end year, and grade.\n",
      "\n",
      "Wait, in the example given, the JSON uses \"start_year\" and \"end_year\", but in the resume, it's written with spaces as \"Feb 23 – Jan 24\". So I think the years should be extracted as strings without spaces. Like \"2023-01\" for start and end. But looking at the example provided by the user, they have \"start Year\": \"Start Year\", which is probably a typo. It should be \"start_year\" in lowercase.\n",
      "\n",
      "Wait, the user's instruction shows:\n",
      "\n",
      "{\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"Degree Name\",\n",
      "      \"university\": \"University Name\",\n",
      "      \"start Year\": \"Start Year\"\n",
      "      \"End Year\": \"End Year\"\n",
      "      \"grade\": \"Provided grade\"\n",
      "    }]\n",
      "}\n",
      "\n",
      "But that seems incorrect because of the typo after \"start Year\". It's missing commas and proper syntax. So I should correct it in my JSON to have proper keys like \"start_year\" and \"end_year\".\n",
      "\n",
      "So each education entry will be an object with:\n",
      "\n",
      "- degree: string\n",
      "- university: string\n",
      "- start_year: string (like \"2023\")\n",
      "- end_year: string\n",
      "- grade: string\n",
      "\n",
      "Now, looking back at the resume:\n",
      "\n",
      "Master in AI and data science from Ottawa University. The dates are Feb 23 – Jan 24, which I think refers to starting in February 2023 and ending in January 2024.\n",
      "\n",
      "Assiut University's entry is Bachelor's degree in bioinformatics with dates Aug 18 – Aug 22. So that would be from August 2018 to August 2022.\n",
      "\n",
      "So the education array should have two objects:\n",
      "\n",
      "1. Master's in AI and Data Science, Ottawa University, start_year \"2023\", end_year \"2024\", grade \"3.48/4.0\" or maybe just 87% as given.\n",
      "\n",
      "Wait, the resume says Overall Percentage: 87%. So should I include both the grade (3.48 out of 4) and the percentage? Probably just one, but since it's provided, it's better to include it as \"grade\": \"3.48/4.0\" or maybe \"Overall Percentage\": \"87%\".\n",
      "\n",
      "But looking at the example in the instructions, it uses \"Provided grade\", so I think it's safer to use the actual numerical value: 3.48 out of 4.0.\n",
      "\n",
      "So for each education entry:\n",
      "\n",
      "- degree: Master's in AI and Data Science\n",
      "- university: Ottawa University\n",
      "- start_year: 2023\n",
      "- end_year: 2024\n",
      "- grade: 3.48/4.0\n",
      "\n",
      "Then the second one:\n",
      "\n",
      "- degree: Bachelor's degree in Bioinformatics\n",
      "- university: Assiut University\n",
      "- start_year: 2018\n",
      "- end_year: 2022\n",
      "- grade: 87%\n",
      "\n",
      "Wait, but in the resume, it says Overall Grade and Overall Percentage. So maybe I should represent the grade as a string with both? Or perhaps just include one.\n",
      "\n",
      "I think for simplicity, since the user's example includes \"grade\": \"Provided grade\", I can take the overall percentage: 87%. Alternatively, take both. But to be accurate, it's better to use the numerical value given.\n",
      "\n",
      "Wait, in the resume, under education, it says Overall Grade: 3.48 out of 4.0 - Overall Percentage: 87%. So perhaps the grade is 3.48/4.0 and the percentage is 87%.\n",
      "\n",
      "So for each entry, include both? Or perhaps only one. The example shows \"grade\": \"Provided grade\", so maybe it's better to put the numerical value as a string.\n",
      "\n",
      "So for the first education:\n",
      "\n",
      "{\n",
      "  \"degree\": \"Master's in AI and Data Science\",\n",
      "  \"university\": \"Ottawa University\",\n",
      "  \"start_year\": \"2023\",\n",
      "  \"end_year\": \"2024\",\n",
      "  \"grade\": \"3.48/4.0\"\n",
      "}\n",
      "\n",
      "Second one:\n",
      "\n",
      "{\n",
      "  \"degree\": \"Bachelor's degree in Bioinformatics\",\n",
      "  \"university\": \"Assiut University\",\n",
      "  \"start_year\": \"2018\",\n",
      "  \"end_year\": \"2022\",\n",
      "  \"grade\": \"87%\"\n",
      "}\n",
      "\n",
      "Wait, but the user's instruction example has only one entry with grade. So perhaps we should take the numerical value as a string.\n",
      "\n",
      "Alternatively, maybe it's better to have both in case. But I think for now, I'll include the overall percentage as the grade.\n",
      "\n",
      "So putting it all together, the JSON would look like:\n",
      "\n",
      "{\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"Master's in AI and Data Science\",\n",
      "      \"university\": \"Ottawa University\",\n",
      "      \"start_year\": \"2023\",\n",
      "      \"end_year\": \"2024\",\n",
      "      \"grade\": \"87%\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Bachelor's degree in Bioinformatics\",\n",
      "      \"university\": \"Assiut University\",\n",
      "      \"start_year\": \"2018\",\n",
      "      \"end_year\": \"2022\",\n",
      "      \"grade\": \"87%\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Wait, but the Master's program has a different grade than the Bachelor's. The resume says Overall Grade: 3.48 out of 4.0 - Overall Percentage: 87%. So I think that refers to the overall average, not specific to each degree.\n",
      "\n",
      "Hmm, this is tricky. Maybe for each education entry, include the respective grades or just the overall?\n",
      "\n",
      "But since it's per program, perhaps we should have separate entries with their own grades. Wait, no, in the resume, the Overall Grade and Overall Percentage are probably referring to the entire bachelor's degree. So maybe it's better to only include one grade at the top.\n",
      "\n",
      "Alternatively, I can include both in case.\n",
      "\n",
      "But considering that the user provided an example where \"grade\" is included as a string, perhaps we should take the overall percentage for each entry? Or not.\n",
      "\n",
      "Wait, no, because each education program has its own grades. So perhaps it's better to include them separately.\n",
      "\n",
      "So in this case:\n",
      "\n",
      "First education (Master's): degree, university, start/end years, grade 3.48/4.0\n",
      "\n",
      "Second education (Bachelor's): same details, with grade 87%\n",
      "\n",
      "Alternatively, the overall percentage is for both degrees? Not sure. But probably not; each program has its own.\n",
      "\n",
      "So I think it's better to include the grade as given for each degree. So Master's: 3.48/4.0, Bachelor's: 87%.\n",
      "\n",
      "Thus, the JSON would have two entries with their respective grades.\n",
      "\n",
      "I'll proceed with that.\n",
      "</think>\n",
      "\n",
      "Here is the JSON representation of the education details based on the provided information:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"Master's in AI and Data Science\",\n",
      "      \"university\": \"Ottawa University\",\n",
      "      \"start_year\": \"2023\",\n",
      "      \"end_year\": \"2024\",\n",
      "      \"grade\": \"3.48/4.0\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Bachelor's degree in Bioinformatics\",\n",
      "      \"university\": \"Assiut University\",\n",
      "      \"start_year\": \"2018\",\n",
      "      \"end_year\": \"2022\",\n",
      "      \"grade\": \"87%\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Execution time: 0:02:48.550877\n"
     ]
    }
   ],
   "source": [
    "model = \"deepseek-r1:8b\"\n",
    "prompt = '''You are an AI assistant specialized in extracting structured information from resumes. Given the following resume text, extract the education part in exactly this JSON format. Here's an example:\n",
    "\n",
    "---\n",
    "{\n",
    "  \"education\": [\n",
    "    {\n",
    "      \"degree\": \"Degree Name\",\n",
    "      \"university\": \"University Name\",\n",
    "      \"start Year\": \"Start Year\"\n",
    "      \"End Year\": \"End Year\"\n",
    "      \"grade\": \"Provided grade\"\n",
    "    }]\n",
    "}\n",
    "---\n",
    "\n",
    "Instructions:\n",
    "1. Maintain the exact JSON structure with correct nesting, this is a top priority.\n",
    "2. Extract all available information while preserving accuracy.\n",
    "4. Ensure all extracted fields are clear and concise.\n",
    "5. The output should be the JSON code only and nothing else.\n",
    "\n",
    "Now, extract the information from this resume:\n",
    "\n",
    "---\\n''' + pdf_text + '''\\n ---'''\n",
    "start = datetime.now()\n",
    "response = ollama.chat(model = model, messages= [{'role':'user', 'content': prompt}],keep_alive=\"20m\")\n",
    "end = datetime.now()\n",
    "\n",
    "ollamaResponse = response['message']['content']\n",
    "\n",
    "print(ollamaResponse)\n",
    "print(f\"Execution time: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f2791c9-a4f9-438b-9723-940d19a7cc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"contactInformation\": {\n",
      "    \"name\": \"Sandy Adel Latef\",\n",
      "    \"phone\": \"+201226267470\",\n",
      "    \"email\": \"sandyadel877047@gmail.com\",\n",
      "    \"location\": \"Ottawa, Canada\"\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"MEng in AI and data science\",\n",
      "      \"university\": \"Ottawa University, Faculty of Engineering\",\n",
      "      \"start Year\": \"Feb 2023\",\n",
      "      \"End Year\": \"Jan 2024\",\n",
      "      \"grade\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Bachelor's degree in bioinformatics\",\n",
      "      \"university\": \"Assiut University, Faculty of Computers and Information\",\n",
      "      \"start Year\": \"Aug 2018\",\n",
      "      \"End Year\": \"Aug 2022\",\n",
      "      \"grade\": \"3.48 out of 4.0 - Overall Percentage: 87%\"\n",
      "    }\n",
      "  ],\n",
      "  \"workExperience\": [\n",
      "    {\n",
      "      \"title\": \"Data engineer intern\",\n",
      "      \"company\": \"Click ITS company\",\n",
      "      \"start date\": \"Jan 2024\",\n",
      "      \"end date\": \"Mar 2024\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Call center agent\",\n",
      "      \"company\": \"Orange Telecommunication Company\",\n",
      "      \"start date\": \"Nov 2022\",\n",
      "      \"end date\": \"Jan 2023\"\n",
      "    }\n",
      "  ],\n",
      "  \"skills\": [\n",
      "    \"Programming\",\n",
      "    \"Python | SQL\",\n",
      "    \"Software engineering\",\n",
      "    \"Data Structure | Relational DB | Problem solving\",\n",
      "    \"Data Science\",\n",
      "    \"Data Analysis | AI | ML | DL | NLP | CV | Statistics | Time Series\",\n",
      "    \"Other\",\n",
      "    \"Git | GitHub | tableau | Dataiku | HPE Data fabric\"\n",
      "  ],\n",
      "  \"languages\": [\n",
      "    \"Arabic\",\n",
      "    \"English\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Execution time: 0:03:04.495900\n"
     ]
    }
   ],
   "source": [
    "model = \"phi4\"\n",
    "prompt = '''You are an AI assistant specialized in extracting structured information from resumes. Given the following resume text, extract key details in exactly this JSON format:\n",
    "\n",
    "---\n",
    "{\n",
    "  \"contactInformation\": {\n",
    "    \"name\": \"Full Name\",\n",
    "    \"phone\": \"Phone Number\",\n",
    "    \"email\": \"Email Address\",\n",
    "    \"location\": \"City, Country\"\n",
    "  },\n",
    "  \"education\": [\n",
    "    {\n",
    "      \"degree\": \"Degree Name\",\n",
    "      \"university\": \"University Name\",\n",
    "      \"start Year\": \"Start Year\"\n",
    "      \"End Year\": \"End Year\"\n",
    "      \"grade\": \"provided grade\"\n",
    "    }\n",
    "  ],\n",
    "  \"workExperience\": [\n",
    "    {\n",
    "      \"title\": \"Job Title\",\n",
    "      \"company\": \"Company Name\",\n",
    "      \"start date\": \"Month/Year\"\n",
    "      \"end date\": \"Month/Year\"\n",
    "      \"end date\"\n",
    "    }\n",
    "  ],\n",
    "  \"skills\": [\n",
    "    \"Skill 1\",\n",
    "    \"Skill 2\",\n",
    "    \"Skill 3\"\n",
    "  ],\n",
    "  \"languages\": [\n",
    "    \"Language 1\",\n",
    "    \"Language 2\"\n",
    "  ]\n",
    "}\n",
    "---\n",
    "\n",
    "Instructions:\n",
    "1. Maintain the exact JSON structure with correct nesting, this is a top priority.\n",
    "2. Extract all available information while preserving accuracy.\n",
    "3. Use standardized formats for dates (`Month Year - Month Year`) and location (`City, Country`).\n",
    "4. Ensure all extracted fields are clear and concise.\n",
    "5. In the \"languages\" section, write only the language name.\n",
    "6. In the \"skills\" section, write individual skills separated by commas.\n",
    "\n",
    "Now, extract the information from this resume:\n",
    "\n",
    "---\\n''' + pdf_text + '''\\n ---'''\n",
    "start = datetime.now()\n",
    "response = ollama.chat(model = model, messages= [{'role':'user', 'content': prompt}],keep_alive=\"20m\")\n",
    "end = datetime.now()\n",
    "\n",
    "ollamaResponse = response['message']['content']\n",
    "\n",
    "print(ollamaResponse)\n",
    "print(f\"Execution time: {end - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6531c0-c120-4c68-ab8d-00869443247a",
   "metadata": {},
   "source": [
    "<font size=\"6\">Groq API</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df0ef966-1135-494a-be6c-ee92accad510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "{\n",
      "  \"contactInformation\": {\n",
      "    \"name\": \"Sandy Adel Latef\",\n",
      "    \"phone\": \"+201226267470\",\n",
      "    \"email\": \"sandyadel877047@gmail.com\",\n",
      "    \"location\": \"Canada\"\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"MEng in AI and data science\",\n",
      "      \"university\": \"Ottawa University\",\n",
      "      \"faculty\": \"Faculty of Engineering\",\n",
      "      \"start Year\": \"February 2023\",\n",
      "      \"End Year\": \"January 2024\",\n",
      "      \"grade\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Bachelor's degree in bioinformatics\",\n",
      "      \"university\": \"Assiut University\",\n",
      "      \"faculty\": \"Faculty of Computers and Information\",\n",
      "      \"start Year\": \"August 2018\",\n",
      "      \"End Year\": \"August 2022\",\n",
      "      \"grade\": \"3.48\"\n",
      "    }\n",
      "  ],\n",
      "  \"workExperience\": [\n",
      "    {\n",
      "      \"title\": \"Data engineer intern\",\n",
      "      \"company\": \"Click ITS company\",\n",
      "      \"start date\": \"January 2024\",\n",
      "      \"end date\": \"March 2024\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Call center agent\",\n",
      "      \"company\": \"Orange Telecommunication Company\",\n",
      "      \"start date\": \"November 2022\",\n",
      "      \"end date\": \"January 2023\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Member\",\n",
      "      \"company\": \"ACM\",\n",
      "      \"start date\": \"August 2018\",\n",
      "      \"end date\": \"August 2022\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Leader\",\n",
      "      \"company\": \"Scout group\",\n",
      "      \"start date\": \"August 2012\",\n",
      "      \"end date\": \"August 2022\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Trainee\",\n",
      "      \"company\": \"Dale Carnage Course\",\n",
      "      \"start date\": \"February 2023\",\n",
      "      \"end date\": \"April 2023\"\n",
      "    }\n",
      "  ],\n",
      "  \"skills\": [\n",
      "    \"Python\",\n",
      "    \"SQL\",\n",
      "    \"Data Structure\",\n",
      "    \"Relational DB\",\n",
      "    \"Problem solving\",\n",
      "    \"Data Analysis\",\n",
      "    \"Artificial Intelligence\",\n",
      "    \"Machine Learning\",\n",
      "    \"Deep Learning\",\n",
      "    \"Natural Language Processing\",\n",
      "    \"Computer Vision\",\n",
      "    \"Statistics\",\n",
      "    \"Time Series\",\n",
      "    \"Git\",\n",
      "    \"GitHub\",\n",
      "    \"Tableau\",\n",
      "    \"Dataiku\",\n",
      "    \"HPE Data fabric\",\n",
      "    \"C++\",\n",
      "    \"Java\",\n",
      "    \"C#\"\n",
      "  ],\n",
      "  \"spoken languages\": [\n",
      "    \"Arabic\",\n",
      "    \"English\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = '''You are an AI assistant specialized in extracting structured information from resumes. Given the following resume text, extract key details in exactly this JSON format. Here's an example:\n",
    "\n",
    "{\n",
    "  \"contactInformation\": {\n",
    "    \"name\": \"Full Name\",\n",
    "    \"phone\": \"Phone Number\",\n",
    "    \"email\": \"Email Address\",\n",
    "    \"location\": \"City, Country\"\n",
    "  },\n",
    "  \"education\": [\n",
    "    {\n",
    "      \"degree\": \"Degree Name\",\n",
    "      \"university\": \"University Name\",\n",
    "      \"faculty\": \"Faculty Name\",\n",
    "      \"start Year\": \"Start Year\",\n",
    "      \"End Year\": \"End Year\",\n",
    "      \"grade\": \"provided grade\"\n",
    "    }\n",
    "  ],\n",
    "  \"workExperience\": [\n",
    "    {\n",
    "      \"title\": \"Job Title\",\n",
    "      \"company\": \"Company Name\",\n",
    "      \"start date\": \"Month Year\",\n",
    "      \"end date\": \"Month Year\"\n",
    "    }\n",
    "  ],\n",
    "  \"skills\": [\n",
    "    \"Skill 1\",\n",
    "    \"Skill 2\",\n",
    "    \"Skill 3\"\n",
    "  ],\n",
    "  \"spoken languages\": [\n",
    "    \"Language 1\",\n",
    "    \"Language 2\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "### **Instructions (Follow Strictly):**\n",
    "1. **Maintain the exact JSON structure with correct nesting**. This is a **top priority**.  \n",
    "2. **Extract all available information while ensuring accuracy**.  \n",
    "3. **Format Dates**: Use `Month Year` format for both start and end dates (e.g., `\"January 2022 - December 2023\"`).  \n",
    "4. **Format Locations**: Use `City, Country` format (e.g., `\"San Francisco, USA\"`).  \n",
    "5. **Spoken Languages**: Include **only** the language names (e.g., `\"English\"`, `\"Spanish\"`).  \n",
    "6. **Skills**: \n",
    "    - Extract and list **all relevant skills**. Check for skills **in any section of the CV**, not just in a dedicated \"Skills\" section.\n",
    "    -Ensure each individual skill is added as a separate element in the \"skills\" list.\n",
    "7. **Grade (GPA Handling)**:\n",
    "   - If a GPA is provided, extract **only the numeric GPA** (e.g., `\"3.48\"` from `\"GPA: 3.48 of 4.00\"`).  \n",
    "   - Do **not** include text like `\"of 4.00\"` or `\"%\"`.  \n",
    "   - If the GPA is not explicitly available, check for a percentage (e.g., `\"85%\" → `\"85\"`).  \n",
    "   - If no grade is found, leave it **blank**.  \n",
    "8. **Abbreviations**: Expand common abbreviations into their full form. Example:\n",
    "   - `\"ML\"` → `\"Machine Learning\"`\n",
    "   - `\"NLP\"` → `\"Natural Language Processing\"`\n",
    "   - `\"AI\"` → `\"Artificial Intelligence\"`\n",
    "9. **If a field is missing, leave it blank** instead of guessing.  \n",
    "10. **Output only valid JSON**:  \n",
    "   - **Do not include any introductory/explanatory text.**  \n",
    "   - **Do not print `json` or any formatting hints before the JSON output.**\n",
    "11. **Phone Numbers**: If multiple phone numbers are found, include only the most relevant one (e.g., the primary number mentioned under contact details or the first valid number found). Ignore duplicates or secondary numbers.\n",
    "'''\n",
    "\n",
    "client = Groq(\n",
    "\n",
    "    api_key= \"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\",\n",
    "\n",
    ")\n",
    "\n",
    "conversation =[\n",
    "    {\n",
    "        \"role\":\"system\",\n",
    "        \"content\": prompt\n",
    "    },\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\": f\"Extract structured information from this resume:\\n\\n{pdf_text}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "CV_query = client.chat.completions.create(\n",
    "\n",
    "    messages=conversation,\n",
    "\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "print(CV_query.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60974608-6d2e-406b-b704-c82baf048215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"skills\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "job_desc = '''Job Description\n",
    "\n",
    "    Tax calculations and preparation of tax forms\n",
    "    Revenue Analyst\n",
    "    Cashing of company checks\n",
    "    Dealing with any third party\n",
    "    Company licenses work with government agencies\n",
    "    Administrative Coordinator\n",
    "    Presence and absence of employees\n",
    "    Overtime worksheets\n",
    "    cost center\n",
    "\n",
    "Job Requirements\n",
    "\n",
    "    B.Sc. in Accounting\n",
    "    Proven experience as an accountant or in a similar financial role\n",
    "    Strong knowledge of tax regulations and experience preparing tax forms\n",
    "    Familiarity with revenue analysis and cost center management\n",
    "    Excellent attention to detail and organizational skills\n",
    "    Strong analytical and problem-solving skills\n",
    "    Ability to manage multiple tasks and prioritize effectively in a fast-paced environment\n",
    "    Strong communication skills for interacting with third parties, employees, and government agencies\n",
    "    Knowledge of payroll processes and overtime calculations\n",
    "    Ability to maintain confidentiality and handle sensitive financial data responsibly\n",
    "    Experience with administrative coordination and basic office management is an advantage\n",
    "\n",
    "\n",
    "We are looking for talented, highly motivated individuals who believe in excellence and are committed to high performance. If you are interested in becoming a part of our professional organization we’d love to hear from you. Check out our list of vacancies and send your resume to mts-hr@mts-mea.com\n",
    "'''\n",
    "\n",
    "prompt = '''You are an AI assistant that extracts required skills from job descriptions.  \n",
    "\n",
    "Given the following job description, extract only the relevant **technical and domain-specific skills** explicitly mentioned in the text, including specific software, tools, technologies, and platforms.  \n",
    "\n",
    "Return the result in **exactly** the following JSON format:  \n",
    "\n",
    "{\n",
    "  \"skills\": [\n",
    "    \"Skill 1\",\n",
    "    \"Skill 2\",\n",
    "    \"Skill 3\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "### **Rules to Follow (Strictly Enforce These):**\n",
    "1. **Only include explicitly mentioned skills** (e.g., `\"Python\"`, `\"Machine Learning\"`, `\"SQL\"`).  \n",
    "2. **Do not include job titles** (e.g., `\"Software Engineer\"`) or generic experience requirements (e.g., `\"experience in AI\"`).  \n",
    "3. **Check all qualification sections carefully** to ensure all technical skills are captured.  \n",
    "4. **Follow the exact JSON structure**—do not add extra fields, explanations, or formatting.  \n",
    "5. **Output only valid JSON**:  \n",
    "   - **Do not include any introductory/explanatory text.**  \n",
    "   - **Do not print `json` or any formatting hints before the JSON output.**  \n",
    "6. **Expand abbreviations where applicable**, ensuring clarity. Example:  \n",
    "   - `\"ML\"` → `\"Machine Learning\"`  \n",
    "   - `\"NLP\"` → `\"Natural Language Processing\"`  \n",
    "   - `\"DL\"` → `\"Deep Learning\"`  \n",
    "7. **If no skills are found, return an empty list (`\"skills\": []`) instead of making assumptions.**  \n",
    "'''\n",
    "#Job Description: \\n''' + job_desc\n",
    "\n",
    "\n",
    "job_conversation = [\n",
    "    {\n",
    "        \"role\":\"system\",\n",
    "        \"content\": prompt\n",
    "    },\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\": f\"Extract structured information from this job description:\\n\\n{job_desc}\"\n",
    "    }\n",
    "]\n",
    "Job_query = client.chat.completions.create(\n",
    "\n",
    "    messages=job_conversation,\n",
    "\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "\n",
    ")\n",
    "\n",
    "print(Job_query.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b538d236-a78d-4864-90ce-dd4ede5cf6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################### CV ###########################\n",
      "{\n",
      "  \"contactInformation\": {\n",
      "    \"name\": \"Sandy Adel Latef\",\n",
      "    \"phone\": \"+201226267470\",\n",
      "    \"email\": \"sandyadel877047@gmail.com\",\n",
      "    \"location\": \"Canada\"\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"MEng in AI and data science\",\n",
      "      \"university\": \"Ottawa University\",\n",
      "      \"faculty\": \"Faculty of Engineering\",\n",
      "      \"start Year\": \"February 2023\",\n",
      "      \"End Year\": \"January 2024\",\n",
      "      \"grade\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Bachelor's degree in bioinformatics\",\n",
      "      \"university\": \"Assiut University\",\n",
      "      \"faculty\": \"Faculty of Computers and Information\",\n",
      "      \"start Year\": \"August 2018\",\n",
      "      \"End Year\": \"August 2022\",\n",
      "      \"grade\": \"3.48\"\n",
      "    }\n",
      "  ],\n",
      "  \"workExperience\": [\n",
      "    {\n",
      "      \"title\": \"Data engineer intern\",\n",
      "      \"company\": \"Click ITS company\",\n",
      "      \"start date\": \"January 2024\",\n",
      "      \"end date\": \"March 2024\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Call center agent\",\n",
      "      \"company\": \"Orange Telecommunication Company\",\n",
      "      \"start date\": \"November 2022\",\n",
      "      \"end date\": \"January 2023\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Member\",\n",
      "      \"company\": \"ACM\",\n",
      "      \"start date\": \"August 2018\",\n",
      "      \"end date\": \"August 2022\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Leader\",\n",
      "      \"company\": \"Scout group\",\n",
      "      \"start date\": \"August 2012\",\n",
      "      \"end date\": \"August 2022\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Trainee\",\n",
      "      \"company\": \"Dale Carnage Course\",\n",
      "      \"start date\": \"February 2023\",\n",
      "      \"end date\": \"April 2023\"\n",
      "    }\n",
      "  ],\n",
      "  \"skills\": [\n",
      "    \"Python\",\n",
      "    \"SQL\",\n",
      "    \"Data Structure\",\n",
      "    \"Relational DB\",\n",
      "    \"Problem solving\",\n",
      "    \"Data Analysis\",\n",
      "    \"Artificial Intelligence\",\n",
      "    \"Machine Learning\",\n",
      "    \"Deep Learning\",\n",
      "    \"Natural Language Processing\",\n",
      "    \"Computer Vision\",\n",
      "    \"Statistics\",\n",
      "    \"Time Series\",\n",
      "    \"Git\",\n",
      "    \"GitHub\",\n",
      "    \"Tableau\",\n",
      "    \"Dataiku\",\n",
      "    \"HPE Data fabric\",\n",
      "    \"C++\",\n",
      "    \"Java\",\n",
      "    \"C#\"\n",
      "  ],\n",
      "  \"spoken languages\": [\n",
      "    \"Arabic\",\n",
      "    \"English\"\n",
      "  ]\n",
      "}\n",
      "########################### JOB ###########################\n",
      "{\n",
      "  \"skills\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "CV_response = CV_query.choices[0].message.content\n",
    "Job_response = Job_query.choices[0].message.content\n",
    "\n",
    "CV = re.search(r'```(.*?)```', CV_response, re.DOTALL)\n",
    "#Job = re.search(r'```(.*?)```', Job_response, re.DOTALL)\n",
    "\n",
    "if CV:\n",
    "    extracted_CV = CV.group(1).strip()\n",
    "# if Job:\n",
    "#     extracted_Job = Job.group(1).strip()\n",
    "\n",
    "extracted_Job = Job_response.strip()   \n",
    "\n",
    "print(\"########################### CV ###########################\")\n",
    "print(extracted_CV)\n",
    "print(\"########################### JOB ###########################\")\n",
    "print(extracted_Job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73ee6fab-94dd-48df-89fa-6cd7da1d8263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contactInformation': {'name': 'Sandy Adel Latef', 'phone': '+201226267470', 'email': 'sandyadel877047@gmail.com', 'location': 'Canada'}, 'education': [{'degree': 'MEng in AI and data science', 'university': 'Ottawa University', 'faculty': 'Faculty of Engineering', 'start Year': 'February 2023', 'End Year': 'January 2024', 'grade': ''}, {'degree': \"Bachelor's degree in bioinformatics\", 'university': 'Assiut University', 'faculty': 'Faculty of Computers and Information', 'start Year': 'August 2018', 'End Year': 'August 2022', 'grade': '3.48'}], 'workExperience': [{'title': 'Data engineer intern', 'company': 'Click ITS company', 'start date': 'January 2024', 'end date': 'March 2024'}, {'title': 'Call center agent', 'company': 'Orange Telecommunication Company', 'start date': 'November 2022', 'end date': 'January 2023'}, {'title': 'Member', 'company': 'ACM', 'start date': 'August 2018', 'end date': 'August 2022'}, {'title': 'Leader', 'company': 'Scout group', 'start date': 'August 2012', 'end date': 'August 2022'}, {'title': 'Trainee', 'company': 'Dale Carnage Course', 'start date': 'February 2023', 'end date': 'April 2023'}], 'skills': ['Python', 'SQL', 'Data Structure', 'Relational DB', 'Problem solving', 'Data Analysis', 'Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Computer Vision', 'Statistics', 'Time Series', 'Git', 'GitHub', 'Tableau', 'Dataiku', 'HPE Data fabric', 'C++', 'Java', 'C#'], 'spoken languages': ['Arabic', 'English']}\n",
      "{'skills': []}\n"
     ]
    }
   ],
   "source": [
    "CV_dict = json.loads(extracted_CV)  # Convert to Python dictionary\n",
    "Job_dict = json.loads(extracted_Job)  # Convert to Python dictionary\n",
    "print(CV_dict)\n",
    "print(Job_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ac1a47-7c22-41c5-9603-f0f31b2e2884",
   "metadata": {},
   "source": [
    "<font size=\"6\">Embeddings</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b15c2e7-6735-41e3-8fa9-1a9126914179",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b2625-78fc-424c-97d5-3d388c21b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"hkunlp/instructor-xl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5560d9ed-ef88-4eb7-a8ef-2ad18ef3c4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "workExperience = [\n",
    "    {\n",
    "      \"company_name\": \"Click ITS company\",\n",
    "      \"start_date\": \"Jan 24\",\n",
    "      \"end_date\": \"Mar 24\",\n",
    "      \"description\": '''Data engineer intern''',\n",
    "      \"job_title\": \"Data engineer intern\",  \n",
    "    },\n",
    "    {\n",
    "      \"company_name\": \"Orange Telecommunication Company\",\n",
    "      \"start_date\": \"Nov 22\",\n",
    "      \"end_date\": \"Jan 23\",\n",
    "      \"description\": '''Call center agent at Orange, help customers and handle angry customers''',\n",
    "      \"job_title\": \"Call center agent\",\n",
    "    },\n",
    "    {\n",
    "      \"company_name\": \"ACM\",\n",
    "      \"start_date\": \"Aug 18\",\n",
    "      \"end_date\": \"Aug 22\",\n",
    "      \"description\": '''Member at ACM, a community which solve problems through programming''',\n",
    "      \"job_title\": \"Member\",\n",
    "    },\n",
    "    {\n",
    "      \"company_name\": \"Scout group\",\n",
    "      \"start_date\": \"Aug 12\",\n",
    "      \"end_date\": \"Aug 22\",\n",
    "      \"description\": '''Leader at the scout group''',\n",
    "      \"job_title\": \"Leader\",\n",
    "    }\n",
    "  ]\n",
    "\n",
    "education = [\n",
    "    {\n",
    "      \"degree\": \"MEng in AI and data science\",\n",
    "      \"school_name\": \"Ottawa University\",\n",
    "      \"field\": \"Faculty of Engineering\",\n",
    "      \"grade\": \"\"\n",
    "    },\n",
    "    {\n",
    "      \"degree\": \"Bachelor's degree in bioinformatics\",\n",
    "      \"school_name\": \"Assiut University\",\n",
    "      \"field\": \"Faculty of Computers and Information\",\n",
    "      \"grade\": \"3.48\"\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3341aee1-d840-46c0-9515-3d81114b96a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"skills\": {\n",
      "    \"Python\": 5,\n",
      "    \"SQL\": 4,\n",
      "    \"Data Structure\": 4,\n",
      "    \"Relational DB\": 4,\n",
      "    \"Problem solving\": 4,\n",
      "    \"Data Analysis\": 5,\n",
      "    \"Artificial Intelligence\": 5,\n",
      "    \"Machine Learning\": 5,\n",
      "    \"Deep Learning\": 5,\n",
      "    \"Natural Language Processing\": 5,\n",
      "    \"Computer Vision\": 5,\n",
      "    \"Statistics\": 4,\n",
      "    \"Time Series\": 5,\n",
      "    \"Git\": 4,\n",
      "    \"GitHub\": 4,\n",
      "    \"Tableau\": 3,\n",
      "    \"Dataiku\": 3,\n",
      "    \"HPE Data fabric\": 3,\n",
      "    \"C++\": 4,\n",
      "    \"Java\": 4,\n",
      "    \"C#\": 4\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "weight_profile = '''You are an expert in analyzing candidate CVs to assess skill proficiency. Given a CV, a list of extracted skills, Education as an array of dictionaries, and\n",
    "Experiences as an array of dictionaries, evaluate the candidate’s experience in each skill and assign a rating from 1 (poor) to 5 (excellent) based on:\n",
    "- Years of experience\n",
    "- Projects or work history related to the skill\n",
    "- Certifications, courses, or achievements\n",
    "\n",
    "Return the result in the following **JSON format**:\n",
    "\n",
    "{\n",
    "  \"skills\": {\n",
    "    \"Skill 1\": rate,\n",
    "    \"Skill 2\": rate\n",
    "  }\n",
    "}\n",
    "\n",
    "### **Rules (Strictly Follow These)**:\n",
    "    1. If the candidate has **no mention** of experience for a skill, rate it **1**.\n",
    "    2. **If the skill is only briefly mentioned** or appears in a general context (e.g., in a skills list but without supporting experience), assign a rating of **2 or 3**.  \n",
    "    3. **If the candidate has moderate experience (some projects or relevant work history),** assign a rating of **4**.  \n",
    "    4. **If the candidate has strong experience (multiple projects, work history, or certifications),** assign a rating of **5**.  \n",
    "    5. **Strict JSON Output**:  \n",
    "       - **No additional text, explanations, or formatting hints** (e.g., do NOT include `\"json\"` at the beginning).  \n",
    "    6. **Use only integer ratings (1-5)**, no decimals or text descriptions.  \n",
    "    7. **Weigh Certifications & Courses**: If a certification or course is mentioned for a skill but no work experience, rate it **at least 3**.  \n",
    "    8. **Weigh Years of Experience**: If a specific number of years is mentioned (e.g., `\"5 years of Python\"`), increase the rating accordingly.\n",
    "    9. Use experience and education from both the CV and the extracted lists.\n",
    "    10. If the same entry exists in both, prefer the CV version (match by meaning, not exact text).\n",
    "    11. DO NOT assume missing skills. Only rate those explicitly mentioned.\n",
    "\n",
    "**Example Input:**\n",
    "---\n",
    "CV:\n",
    "\"Assiut University, Faculty of Computers and Information, Egypt Aug 18 – Aug 22\n",
    "Bachelor's degree in bioinformatics.Overall Grade: 3.48 out of 4.0.\n",
    "I have worked as a Data Scientist at Microsoft for 5 years, primarily using Python and TensorFlow for Machine Learning. I also have experience with SQL databases and AWS cloud services. Recently, I completed a certification in NLP.\"\n",
    "\n",
    "Extracted Skills:\n",
    "[\"Python\", \"Machine Learning\", \"SQL\", \"AWS\", \"NLP\", \"Deep Learning\"]\n",
    "\n",
    "Extracted Experience:\n",
    "[{\"company_name\": \"Microsoft\",\n",
    "\"start_date\": \"2020\",\n",
    "\"end_date\": \"2025\",\n",
    "\"description\": \"I have been working as a Data Scientist in Microsoft for 5 years, primarily using Python and TensorFlow for Machine Learning.\",\n",
    "\"job_title\": \"Data Scientist\"}]\n",
    "\n",
    "Extracted Education:\n",
    "[{\"school_name\": \"Assiut University\",\n",
    "\"field\": \"Faculty of Computers and Information\",\n",
    "\"degree\": \"Bachelor's degree in bioinformatics\",\n",
    "\"grade\": \"3.48\"}]\n",
    "\n",
    "**Expected Output:**\n",
    "---\n",
    "{\n",
    "  \"skills\": {\n",
    "    \"Python\": 5,\n",
    "    \"Machine Learning\": 5,\n",
    "    \"SQL\": 4,\n",
    "    \"AWS\": 4,\n",
    "    \"NLP\": 5,\n",
    "    \"Deep Learning\": 2\n",
    "  }\n",
    "}\n",
    "'''\n",
    "profile_conversation = [\n",
    "    {\n",
    "        \"role\":\"system\",\n",
    "        \"content\": weight_profile\n",
    "    },\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\":f\"Now, analyze the following CV and extracted skills, experience, and education then return the JSON response.\\nCV:\\n{pdf_text}\\n\\nExtracted Skills:\\n{CV_dict[\"skills\"]}\\n\\nExtracted Experience:\\n{workExperience}\\n\\nExtracted Education:\\n{education}\"\n",
    "    }\n",
    "]\n",
    "profile_weight_query = client.chat.completions.create(\n",
    "\n",
    "    messages=profile_conversation,\n",
    "\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "\n",
    ")\n",
    "\n",
    "print(profile_weight_query.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "79801abe-b0c7-416b-98aa-517a2a1a8696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"skills\": {\n",
      "    \"SQL\": 5,\n",
      "    \"Tableau\": 4,\n",
      "    \"Data Modeling\": 4,\n",
      "    \"Data Design\": 4,\n",
      "    \"Power BI\": 5,\n",
      "    \"DWH\": 3,\n",
      "    \"SSIS\": 3,\n",
      "    \"Power query\": 3,\n",
      "    \"Big Data\": 2,\n",
      "    \"SSAS\": 3,\n",
      "    \"Excel\": 4,\n",
      "    \"Statistics\": 3,\n",
      "    \"SSRS\": 3,\n",
      "    \"ETL\": 3,\n",
      "    \"Python\": 3\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "weight_cv = '''You are an expert in analyzing candidate CVs to assess skill proficiency. Given a CV and a list of extracted skills, evaluate the candidate’s experience in each skill and assign a rating from 1 (poor) to 5 (excellent) based on:\n",
    "- Years of experience\n",
    "- Projects or work history related to the skill\n",
    "- Certifications, courses, or achievements\n",
    "\n",
    "Return the result in the following **JSON format**:\n",
    "\n",
    "{\n",
    "  \"skills\": {\n",
    "    \"Skill 1\": rate,\n",
    "    \"Skill 2\": rate\n",
    "  }\n",
    "}\n",
    "\n",
    "### **Rules (Strictly Follow These)**:\n",
    "1. If the candidate has **no mention** of experience for a skill, rate it **1**.\n",
    "2. **If the skill is only briefly mentioned** or appears in a general context (e.g., in a skills list but without supporting experience), assign a rating of **2 or 3**.  \n",
    "3. **If the candidate has moderate experience (some projects or relevant work history),** assign a rating of **4**.  \n",
    "4. **If the candidate has strong experience (multiple projects, work history, or certifications),** assign a rating of **5**.  \n",
    "5. **Strict JSON Output**:  \n",
    "   - **No additional text, explanations, or formatting hints** (e.g., do NOT include `\"json\"` at the beginning).  \n",
    "6. **Use only integer ratings (1-5)**, no decimals or text descriptions.  \n",
    "7. **Weigh Certifications & Courses**: If a certification or course is mentioned for a skill but no work experience, rate it **at least 3**.  \n",
    "8. **Weigh Years of Experience**: If a specific number of years is mentioned (e.g., `\"5 years of Python\"`), increase the rating accordingly.  \n",
    "\n",
    "\n",
    "**Example Input:**\n",
    "---\n",
    "CV:\n",
    "\"I have been working as a Data Scientist for 5 years, primarily using Python and TensorFlow for Machine Learning. I also have experience with SQL databases and AWS cloud services. Recently, I completed a certification in NLP.\"\n",
    "\n",
    "Extracted Skills:\n",
    "[\"Python\", \"Machine Learning\", \"SQL\", \"AWS\", \"NLP\", \"Deep Learning\"]\n",
    "\n",
    "**Expected Output:**\n",
    "---\n",
    "{\n",
    "  \"skills\": {\n",
    "    \"Python\": 5,\n",
    "    \"Machine Learning\": 5,\n",
    "    \"SQL\": 4,\n",
    "    \"AWS\": 4,\n",
    "    \"NLP\": 5,\n",
    "    \"Deep Learning\": 2\n",
    "  }\n",
    "}\n",
    "'''\n",
    "\n",
    "cv_weighting_conversation = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": weight_cv\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Analyze the following CV and extracted skills and return the JSON response.\\n\\nCV:\\n{pdf_text}\\n\\nExtracted Skills:\\n{CV_dict[\"skills\"]}\"\n",
    "    }\n",
    "]\n",
    "CV_weight_query = client.chat.completions.create(\n",
    "\n",
    "    messages=cv_weighting_conversation,\n",
    "\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "\n",
    ")\n",
    "\n",
    "print(CV_weight_query.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49720c66-72d7-4803-9de3-35437fd2d3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41375414\n"
     ]
    }
   ],
   "source": [
    "# CV_skills_embed = model.encode(CV_dict['skills'])\n",
    "# Job_skills_embed = model.encode(Job_dict['skills'])\n",
    "\n",
    "machine = {\n",
    "    \"Machine Learning\":5.0,\n",
    "    \"Python\":5.0,\n",
    "    \"TensorFlow\":5.0,\n",
    "    \"PyTorch\":5.0,\n",
    "    \"Scikit-learn\":5.0,\n",
    "    \"Data Preprocessing\":4.0,\n",
    "    \"Feature Engineering\":4.0,\n",
    "    \"Model Evaluation\":4.0,\n",
    "    \"Cloud Platforms\":4.0,\n",
    "    \"Amazon Web Services\":4.0,\n",
    "    \"Google Cloud Platform\":4.0,\n",
    "    \"Microsoft Azure\":4.0,\n",
    "    \"Artificial Intelligence\":5.0\n",
    "}\n",
    "\n",
    "back = {\n",
    "    \"Node.js\":5.0,\n",
    "    \"RESTful APIs\":5.0,\n",
    "    \"MongoDB\":5.0,\n",
    "    \"Express.js\":5.0,\n",
    "    \"Git\":5.0,\n",
    "    \"Asynchronous Programming\":4.0,\n",
    "    \"Event-Driven Architecture\":4.0,\n",
    "    \"Microservices Architecture\":3.0,\n",
    "    \"Cloud Platforms\":2.0,\n",
    "    \"Containerization\":2.0,\n",
    "    \"Kubernetes\":2.0,\n",
    "    \"AWS\":2.0,\n",
    "    \"Azure\":2.0\n",
    "    }\n",
    "\n",
    "analysis ={\n",
    "    \"SQL\":5.0,\n",
    "    \"Python\":5.0,\n",
    "    \"R\":5.0,\n",
    "    \"Tableau\":5.0,\n",
    "    \"Power BI\":5.0,\n",
    "    \"Google Looker Studio\":5.0,\n",
    "    \"Statistical Analysis\":3.0,\n",
    "    \"Machine Learning\":2.0,\n",
    "    \"AWS\":1.0,\n",
    "    \"Google Cloud\":1.0\n",
    "}\n",
    "\n",
    "accounting ={\n",
    "    \"Accounting\":5.0,\n",
    "    \"Tax regulations\":5.0,\n",
    "    \"Tax forms preparation\":5.0,\n",
    "    \"Revenue analysis\":5.0,\n",
    "    \"Cost center management\":5.0,\n",
    "    \"Payroll processes\":5.0,\n",
    "    \"Overtime calculations\":5.0\n",
    "}\n",
    "\n",
    "skills_rating = {\n",
    "    \"Python\": 5,\n",
    "    \"SQL\": 4,\n",
    "    \"Data Structure\": 4,\n",
    "    \"Relational DB\": 4,\n",
    "    \"Problem solving\": 4,\n",
    "    \"Data Analysis\": 4,\n",
    "    \"Artificial Intelligence\": 5,\n",
    "    \"Machine Learning\": 5,\n",
    "    \"Deep Learning\": 5,\n",
    "    \"Natural Language Processing\": 5,\n",
    "    \"Computer Vision\": 5,\n",
    "    \"Statistics\": 4,\n",
    "    \"Time Series\": 4,\n",
    "    \"Git\": 4,\n",
    "    \"GitHub\": 4,\n",
    "    \"Tableau\": 3,\n",
    "    \"Dataiku\": 3,\n",
    "    \"HPE Data fabric\": 3,\n",
    "    \"C++\": 3,\n",
    "    \"Java\": 3,\n",
    "    \"C#\": 3\n",
    "  }\n",
    "\n",
    "CV_skills_embed = {skill: model.encode(skill)for skill in CV_dict['skills']}\n",
    "Job_skills_embed = {skill: model.encode(skill)for skill,weight in accounting.items()}\n",
    "\n",
    "\n",
    "def weighted_embed_vec(skill_dict, embedding):\n",
    "    total_weight = sum(skill_dict.values())\n",
    "    weighted_sum = sum(embedding[skill] * weight for skill,weight in skill_dict.items())\n",
    "    return weighted_sum/total_weight\n",
    "\n",
    "weighted_job = weighted_embed_vec(accounting, Job_skills_embed)\n",
    "weighted_CV = weighted_embed_vec(skills_rating, CV_skills_embed)\n",
    "# CV_skills_embed = np.mean(model.encode(CV_dict['skills']), axis=0)\n",
    "similarities = cosine_similarity([weighted_job], [weighted_CV])[0][0]\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c27cf424-95c0-4691-9a74-157c40bc3f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17708412]\n"
     ]
    }
   ],
   "source": [
    "embedding = model.encode([\"Power BI\", \"C++\"])\n",
    "similarities = cosine_similarity([embedding[0]], [embedding[1]])[0]\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7788a672-0b8e-4bf9-a307-7dc58defa067",
   "metadata": {},
   "source": [
    "<font size=\"6\">Testing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea8e9b0-9bc0-431c-ab3e-10d1ea300690",
   "metadata": {},
   "source": [
    "<font size=\"4\">Converting CVs to text</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95aa3e07-bf3b-4f07-baaa-19f984dca7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CVs_directory = \"F:\\\\GPResources\\\\New CVs\"\n",
    "CVs_list = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72d87b16-f4b9-45df-a175-7d7adba9ff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CVs_list_from_path(pdfs_path):  \n",
    "    CVs_files = os.listdir(pdfs_path)\n",
    "    for file_name in tqdm(CVs_files, \"Processing CVs...\"):\n",
    "        file_path = os.path.join(pdfs_path,file_name)\n",
    "        CV_txt = extract_text_from_pdf(file_path)\n",
    "        CVs_list[f\"{file_name}\"] = CV_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3650b0c7-e551-485c-ac39-27df31b0af32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CVs...: 100%|███████████████████████████████████████████████████████████████| 95/95 [00:37<00:00,  2.55it/s]\n"
     ]
    }
   ],
   "source": [
    "CVs_list_from_path(CVs_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83b9d50c-d177-4ef4-b71d-c720ff4fdd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CVs_list.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "870445fb-f2e2-439d-9033-540e92222883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_query successful\n",
      "profile_weight_query successful\n",
      "{\n",
      "  \"skills\": {\n",
      "    \"Data Warehousing\": 4,\n",
      "    \"Data Modeling\": 4,\n",
      "    \"SQL Service Reporting System\": 4,\n",
      "    \"Mathematics and Statistics\": 3,\n",
      "    \"Predictive Analytics\": 3,\n",
      "    \"Data Visualizing\": 4,\n",
      "    \"C#\": 4,\n",
      "    \"Python\": 4,\n",
      "    \"Java\": 2,\n",
      "    \"Power Bi\": 4,\n",
      "    \"Microsoft Excel\": 2,\n",
      "    \"Matplotlib\": 2,\n",
      "    \"Seaborn\": 2,\n",
      "    \"SSRS\": 4\n",
      "  }\n",
      "}\n",
      "{'skills': {'Data Warehousing': 4, 'Data Modeling': 4, 'SQL Service Reporting System': 4, 'Mathematics and Statistics': 3, 'Predictive Analytics': 3, 'Data Visualizing': 4, 'C#': 4, 'Python': 4, 'Java': 2, 'Power Bi': 4, 'Microsoft Excel': 2, 'Matplotlib': 2, 'Seaborn': 2, 'SSRS': 4}}\n",
      "1-ibrahim Ahmed-CV.pdf\n",
      "CV_query successful\n",
      "profile_weight_query successful\n",
      "```json\n",
      "{\n",
      "  \"skills\": {\n",
      "    \"DBMS\": 4,\n",
      "    \"Power BI\": 5,\n",
      "    \"Storytelling With Data\": 4,\n",
      "    \"Python\": 3,\n",
      "    \"Data Warehouse Architect\": 4,\n",
      "    \"Excel\": 4,\n",
      "    \"Data Visualization\": 4,\n",
      "    \"Statistic\": 3,\n",
      "    \"SQL\": 4,\n",
      "    \"Pivot Table\": 3,\n",
      "    \"Power Point\": 2,\n",
      "    \"Pandas\": 3,\n",
      "    \"SSIS\": 3,\n",
      "    \"SSAS\": 2,\n",
      "    \"SSRS\": 2,\n",
      "    \"Power Pivot\": 2,\n",
      "    \"Canva\": 1,\n",
      "    \"Plotly\": 1,\n",
      "    \"ETL\": 3,\n",
      "    \"Power Query\": 3,\n",
      "    \"Scipy\": 1,\n",
      "    \"Dax\": 3,\n",
      "    \"Google Sheet\": 2,\n",
      "    \"Machine Learning\": 3,\n",
      "    \"Natural Language Processing\": 1\n",
      "  }\n",
      "}\n",
      "```\n",
      "{'skills': {'DBMS': 4, 'Power BI': 5, 'Storytelling With Data': 4, 'Python': 3, 'Data Warehouse Architect': 4, 'Excel': 4, 'Data Visualization': 4, 'Statistic': 3, 'SQL': 4, 'Pivot Table': 3, 'Power Point': 2, 'Pandas': 3, 'SSIS': 3, 'SSAS': 2, 'SSRS': 2, 'Power Pivot': 2, 'Canva': 1, 'Plotly': 1, 'ETL': 3, 'Power Query': 3, 'Scipy': 1, 'Dax': 3, 'Google Sheet': 2, 'Machine Learning': 3, 'Natural Language Processing': 1}}\n",
      "AbdElrahman Mohamed Faheem-Data Engineer.pdf\n",
      "CV_query fail, retrying...\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jmdp7mmme76b1c0kx57ns4nb` service tier `on_demand` on : Limit 100000, Used 98834, Requested 1740. Please try again in 8m15.659s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': '', 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 108\u001b[0m\n\u001b[0;32m     96\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m120\u001b[39m)\n\u001b[0;32m     97\u001b[0m     conversation \u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     98\u001b[0m         {\n\u001b[0;32m     99\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m         }\n\u001b[0;32m    106\u001b[0m     ]\n\u001b[1;32m--> 108\u001b[0m     CV_query \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    109\u001b[0m     \n\u001b[0;32m    110\u001b[0m         messages\u001b[38;5;241m=\u001b[39mconversation,\n\u001b[0;32m    111\u001b[0m     \n\u001b[0;32m    112\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama-3.3-70b-versatile\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    113\u001b[0m     \n\u001b[0;32m    114\u001b[0m     )\n\u001b[0;32m    115\u001b[0m cv_response \u001b[38;5;241m=\u001b[39m CV_query\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    116\u001b[0m match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*(?:json)?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*(.*?)```\u001b[39m\u001b[38;5;124m'\u001b[39m, cv_response, re\u001b[38;5;241m.\u001b[39mDOTALL)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\groq\\resources\\chat\\completions.py:322\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, seed, service_tier, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    199\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/openai/v1/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    324\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    325\u001b[0m             {\n\u001b[0;32m    326\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    327\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    328\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    329\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    330\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    332\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    333\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m    334\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    335\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    336\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    337\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    338\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_format,\n\u001b[0;32m    339\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    340\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    341\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m    342\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    343\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    344\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    345\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    346\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    347\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    348\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    349\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    350\u001b[0m             },\n\u001b[0;32m    351\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    352\u001b[0m         ),\n\u001b[0;32m    353\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    354\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    355\u001b[0m         ),\n\u001b[0;32m    356\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    357\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    359\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\groq\\_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1254\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1261\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1263\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1264\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1265\u001b[0m     )\n\u001b[1;32m-> 1266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\groq\\_base_client.py:958\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    956\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 958\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    959\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    960\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    961\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    962\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    963\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m    964\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\groq\\_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1070\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jmdp7mmme76b1c0kx57ns4nb` service tier `on_demand` on : Limit 100000, Used 98834, Requested 1740. Please try again in 8m15.659s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': '', 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "sim = []\n",
    "for i in CVs_list.keys():\n",
    "    cv = CVs_list[i]  \n",
    "    client = Groq(\n",
    "    \n",
    "        api_key= \"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\",\n",
    "    \n",
    "    )\n",
    "    \n",
    "    prompt = '''You are an AI assistant specialized in extracting structured information from resumes. Given the following resume text, extract key details in exactly this JSON format. Here's an example:\n",
    "    \n",
    "    {\n",
    "      \"contactInformation\": {\n",
    "        \"name\": \"Full Name\",\n",
    "        \"phone\": \"Phone Number\",\n",
    "        \"email\": \"Email Address\",\n",
    "        \"location\": \"City, Country\"\n",
    "      },\n",
    "      \"education\": [\n",
    "        {\n",
    "          \"degree\": \"Degree Name\",\n",
    "          \"university\": \"University Name\",\n",
    "          \"faculty\": \"Faculty Name\",\n",
    "          \"start Year\": \"Start Year\",\n",
    "          \"End Year\": \"End Year\",\n",
    "          \"grade\": \"provided grade\"\n",
    "        }\n",
    "      ],\n",
    "      \"workExperience\": [\n",
    "        {\n",
    "          \"title\": \"Job Title\",\n",
    "          \"company\": \"Company Name\",\n",
    "          \"start date\": \"Month Year\",\n",
    "          \"end date\": \"Month Year\"\n",
    "        }\n",
    "      ],\n",
    "      \"skills\": [\n",
    "        \"Skill 1\",\n",
    "        \"Skill 2\",\n",
    "        \"Skill 3\"\n",
    "      ],\n",
    "      \"spoken languages\": [\n",
    "        \"Language 1\",\n",
    "        \"Language 2\"\n",
    "      ]\n",
    "    }\n",
    "    \n",
    "    ### **Instructions (Follow Strictly):**\n",
    "    1. **Maintain the exact JSON structure with correct nesting**. This is a **top priority**.  \n",
    "    2. **Extract all available information while ensuring accuracy**.  \n",
    "    3. **Format Dates**: Use `Month Year` format for both start and end dates (e.g., `\"January 2022 - December 2023\"`).  \n",
    "    4. **Format Locations**: Use `City, Country` format (e.g., `\"San Francisco, USA\"`).  \n",
    "    5. **Spoken Languages**: Include **only** the language names (e.g., `\"English\"`, `\"Spanish\"`).  \n",
    "    6. **Skills**: \n",
    "        -Extract and list **all relevant skills**. Check for skills **in any section of the CV**, not just in a dedicated \"Skills\" section.\n",
    "        -Ensure each individual skill is added as a separate element in the \"skills\" list.\n",
    "    7. **Grade (GPA Handling)**:\n",
    "       - If a GPA is provided, extract **only the numeric GPA** (e.g., `\"3.48\"` from `\"GPA: 3.48 of 4.00\"`).  \n",
    "       - Do **not** include text like `\"of 4.00\"` or `\"%\"`.  \n",
    "       - If the GPA is not explicitly available, check for a percentage (e.g., `\"85%\" → `\"85\"`).  \n",
    "       - If no grade is found, leave it **blank**.  \n",
    "    8. **Abbreviations**: Expand common abbreviations into their full form. Example:\n",
    "       - `\"ML\"` → `\"Machine Learning\"`\n",
    "       - `\"NLP\"` → `\"Natural Language Processing\"`\n",
    "    9. **If a field is missing, leave it blank** instead of guessing.  \n",
    "    10. **Output only valid JSON**:  \n",
    "       - **Do not include any introductory/explanatory text.**  \n",
    "       - **Do not print `json` or any formatting hints before the JSON output.**\n",
    "    11. **Phone Numbers**: If multiple phone numbers are found, include only the most relevant one (e.g., the primary number mentioned under contact details or the first valid number found). Ignore duplicates or secondary numbers.\n",
    "    '''\n",
    "\n",
    "    CV_query = None\n",
    "    try:\n",
    "        conversation =[\n",
    "            {\n",
    "                \"role\":\"system\",\n",
    "                \"content\": prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": f\"Extract structured information from this resume:\\n\\n{cv}\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        CV_query = client.chat.completions.create(\n",
    "        \n",
    "            messages=conversation,\n",
    "        \n",
    "            model=\"llama-3.3-70b-versatile\",\n",
    "        \n",
    "        )\n",
    "        print(\"CV_query successful\")\n",
    "        time.sleep(60)\n",
    "    except:\n",
    "        print(\"CV_query fail, retrying...\")\n",
    "        time.sleep(120)\n",
    "        conversation =[\n",
    "            {\n",
    "                \"role\":\"system\",\n",
    "                \"content\": prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": f\"Extract structured information from this resume:\\n\\n{cv}\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        CV_query = client.chat.completions.create(\n",
    "        \n",
    "            messages=conversation,\n",
    "        \n",
    "            model=\"llama-3.3-70b-versatile\",\n",
    "        \n",
    "        )\n",
    "    cv_response = CV_query.choices[0].message.content\n",
    "    match = re.search(r'```\\s*(?:json)?\\s*(.*?)```', cv_response, re.DOTALL)\n",
    "    cv_text = match.group(1).strip() if match else cv_response\n",
    "\n",
    "    CV_dict = json.loads(cv_text)\n",
    "\n",
    "\n",
    "    weight_profile = '''You are an expert in analyzing candidate CVs to assess skill proficiency. Given a CV, a list of extracted skills, Education as an array of dictionaries, and\n",
    "    Experiences as an array of dictionaries, evaluate the candidate’s experience in each skill and assign a rating from 1 (poor) to 5 (excellent) based on:\n",
    "    - Years of experience\n",
    "    - Projects or work history related to the skill\n",
    "    - Certifications, courses, or achievements\n",
    "    \n",
    "    Return the result in the following **JSON format**:\n",
    "    \n",
    "    {\n",
    "      \"skills\": {\n",
    "        \"Skill 1\": rate,\n",
    "        \"Skill 2\": rate\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    ### **Rules (Strictly Follow These)**:\n",
    "        1. If the candidate has **no mention** of experience for a skill, rate it **1**.\n",
    "        2. **If the skill is only briefly mentioned** or appears in a general context (e.g., in a skills list but without supporting experience), assign a rating of **2 or 3**.  \n",
    "        3. **If the candidate has moderate experience (some projects or relevant work history),** assign a rating of **4**.  \n",
    "        4. **If the candidate has strong experience (multiple projects, work history, or certifications),** assign a rating of **5**.  \n",
    "        5. **Strict JSON Output**:  \n",
    "           - **No additional text, explanations, or formatting hints** (e.g., do NOT include `\"json\"` at the beginning).  \n",
    "        6. **Use only integer ratings (1-5)**, no decimals or text descriptions.  \n",
    "        7. **Weigh Certifications & Courses**: If a certification or course is mentioned for a skill but no work experience, rate it **at least 3**.  \n",
    "        8. **Weigh Years of Experience**: If a specific number of years is mentioned (e.g., `\"5 years of Python\"`), increase the rating accordingly.\n",
    "        9. Use experience and education from both the CV and the extracted lists.\n",
    "        10. If the same entry exists in both, prefer the CV version (match by meaning, not exact text).\n",
    "        11. DO NOT assume missing skills. Only rate those explicitly mentioned.\n",
    "    \n",
    "    **Example Input:**\n",
    "    ---\n",
    "    CV:\n",
    "    \"Assiut University, Faculty of Computers and Information, Egypt Aug 18 – Aug 22\n",
    "    Bachelor's degree in bioinformatics.Overall Grade: 3.48 out of 4.0.\n",
    "    I have worked as a Data Scientist at Microsoft for 5 years, primarily using Python and TensorFlow for Machine Learning. I also have experience with SQL databases and AWS cloud services. Recently, I completed a certification in NLP.\"\n",
    "    \n",
    "    Extracted Skills:\n",
    "    [\"Python\", \"Machine Learning\", \"SQL\", \"AWS\", \"NLP\", \"Deep Learning\"]\n",
    "    \n",
    "    Extracted Experience:\n",
    "    [{\"company_name\": \"Microsoft\",\n",
    "    \"start_date\": \"2020\",\n",
    "    \"end_date\": \"2025\",\n",
    "    \"description\": \"I have been working as a Data Scientist in Microsoft for 5 years, primarily using Python and TensorFlow for Machine Learning.\",\n",
    "    \"job_title\": \"Data Scientist\"}]\n",
    "    \n",
    "    Extracted Education:\n",
    "    [{\"school_name\": \"Assiut University\",\n",
    "    \"field\": \"Faculty of Computers and Information\",\n",
    "    \"degree\": \"Bachelor's degree in bioinformatics\",\n",
    "    \"grade\": \"3.48\"}]\n",
    "    \n",
    "    **Expected Output:**\n",
    "    ---\n",
    "    {\n",
    "      \"skills\": {\n",
    "        \"Python\": 5,\n",
    "        \"Machine Learning\": 5,\n",
    "        \"SQL\": 4,\n",
    "        \"AWS\": 4,\n",
    "        \"NLP\": 5,\n",
    "        \"Deep Learning\": 2\n",
    "      }\n",
    "    }\n",
    "    '''\n",
    "    profile_weight_query = None\n",
    "    try:\n",
    "        profile_conversation = [\n",
    "                {\n",
    "                    \"role\":\"system\",\n",
    "                    \"content\": weight_profile\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":f\"Now, analyze the following CV and extracted skills, experience, and education then return the JSON response.\\nCV:\\n{cv}\\n\\nExtracted Skills:\\n{CV_dict[\"skills\"]}\\n\\nExtracted Experience:\\n{workExperience}\\n\\nExtracted Education:\\n{education}\"\n",
    "                }\n",
    "            ]\n",
    "        profile_weight_query = client.chat.completions.create(\n",
    "            \n",
    "                messages=profile_conversation,\n",
    "            \n",
    "                model=\"llama-3.3-70b-versatile\",\n",
    "            \n",
    "            )\n",
    "        print(\"profile_weight_query successful\")\n",
    "        time.sleep(60)\n",
    "    except:\n",
    "        print(\"profile_weight_query fail, retrying...\")\n",
    "        time.sleep(120)\n",
    "        profile_conversation = [\n",
    "                {\n",
    "                    \"role\":\"system\",\n",
    "                    \"content\": weight_profile\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":f\"Now, analyze the following CV and extracted skills, experience, and education then return the JSON response.\\nCV:\\n{cv}\\n\\nExtracted Skills:\\n{CV_dict[\"skills\"]}\\n\\nExtracted Experience:\\n{CV_dict[\"workExperience\"]}\\n\\nExtracted Education:\\n{CV_dict[\"education\"]}\"\n",
    "                }\n",
    "            ]\n",
    "        profile_weight_query = client.chat.completions.create(\n",
    "            \n",
    "                messages=profile_conversation,\n",
    "            \n",
    "                model=\"llama-3.3-70b-versatile\",\n",
    "            \n",
    "            )\n",
    "    profile_weight_query_response = profile_weight_query.choices[0].message.content\n",
    "    print(profile_weight_query_response)\n",
    "    match = re.search(r'```\\s*(?:json)?\\s*(.*?)```', profile_weight_query_response, re.DOTALL)\n",
    "    profile_weight_query_text = match.group(1).strip() if match else profile_weight_query_response\n",
    "    weighted_profile = json.loads(profile_weight_query_text)\n",
    "    print(weighted_profile)\n",
    "    CV_skills_embed = {skill: model.encode(skill)for skill in CV_dict['skills']}\n",
    "    Job_skills_embed = {skill: model.encode(skill)for skill,weight in accounting.items()}\n",
    "    \n",
    "    \n",
    "    def weighted_embed_vec(skill_dict, embedding,digit):\n",
    "        if digit:\n",
    "            total_weight = sum(skill_dict['skills'].values())\n",
    "            weighted_sum = sum(embedding[skill] * weight for skill,weight in skill_dict['skills'].items())\n",
    "        else:\n",
    "            total_weight = sum(skill_dict.values())\n",
    "            weighted_sum = sum(embedding[skill] * weight for skill,weight in skill_dict.items())\n",
    "        return weighted_sum/total_weight\n",
    "    \n",
    "    weighted_job = weighted_embed_vec(accounting, Job_skills_embed,0)\n",
    "    weighted_CV = weighted_embed_vec(weighted_profile, CV_skills_embed,1)\n",
    "    similarities = sim.append(cosine_similarity([weighted_job], [weighted_CV])[0][0])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ab5d45-2580-4002-94ec-fca1d55cf957",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee34a09-7ac6-439d-8e19-b8428ee3c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d5a39e75-5521-4b3b-afeb-0329df700c97",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[234], line 82\u001b[0m\n\u001b[0;32m      1\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124m{\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontactInformation\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m{\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;124m  ]\u001b[39m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 82\u001b[0m f \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*(?:json)?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*(.*?)```\u001b[39m\u001b[38;5;124m'\u001b[39m, t, re\u001b[38;5;241m.\u001b[39mDOTALL)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(f)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "t = \"\"\"\n",
    "{\n",
    "  \"contactInformation\": {\n",
    "    \"name\": \"Sandy Adel Latef\",\n",
    "    \"phone\": \"+201226267470\",\n",
    "    \"email\": \"sandyadel877047@gmail.com\",\n",
    "    \"location\": \"Ottawa, Canada\"\n",
    "  },\n",
    "  \"education\": [\n",
    "    {\n",
    "      \"degree\": \"MEng in AI and data science\",\n",
    "      \"university\": \"Ottawa University\",\n",
    "      \"faculty\": \"Faculty of Engineering\",\n",
    "      \"start Year\": \"February 2023\",\n",
    "      \"End Year\": \"January 2024\",\n",
    "      \"grade\": \"\"\n",
    "    },\n",
    "    {\n",
    "      \"degree\": \"Bachelor's degree in bioinformatics\",\n",
    "      \"university\": \"Assiut University\",\n",
    "      \"faculty\": \"Faculty of Computers and Information\",\n",
    "      \"start Year\": \"August 2018\",\n",
    "      \"End Year\": \"August 2022\",\n",
    "      \"grade\": \"3.48\"\n",
    "    }\n",
    "  ],\n",
    "  \"workExperience\": [\n",
    "    {\n",
    "      \"title\": \"Data engineer intern\",\n",
    "      \"company\": \"Click ITS company\",\n",
    "      \"start date\": \"January 2024\",\n",
    "      \"end date\": \"March 2024\"\n",
    "    },\n",
    "    {\n",
    "      \"title\": \"Call center agent\",\n",
    "      \"company\": \"Orange Telecommunication Company\",\n",
    "      \"start date\": \"November 2022\",\n",
    "      \"end date\": \"January 2023\"\n",
    "    },\n",
    "    {\n",
    "      \"title\": \"Member\",\n",
    "      \"company\": \"ACM\",\n",
    "      \"start date\": \"August 2018\",\n",
    "      \"end date\": \"August 2022\"\n",
    "    },\n",
    "    {\n",
    "      \"title\": \"Leader\",\n",
    "      \"company\": \"Scout group\",\n",
    "      \"start date\": \"August 2012\",\n",
    "      \"end date\": \"August 2022\"\n",
    "    }\n",
    "  ],\n",
    "  \"skills\": [\n",
    "    \"Python\",\n",
    "    \"SQL\",\n",
    "    \"Data Structure\",\n",
    "    \"Relational DB\",\n",
    "    \"Problem solving\",\n",
    "    \"Data Analysis\",\n",
    "    \"Artificial Intelligence\",\n",
    "    \"Machine Learning\",\n",
    "    \"Deep Learning\",\n",
    "    \"Natural Language Processing\",\n",
    "    \"Computer Vision\",\n",
    "    \"Statistics\",\n",
    "    \"Time Series\",\n",
    "    \"Git\",\n",
    "    \"GitHub\",\n",
    "    \"Tableau\",\n",
    "    \"Dataiku\",\n",
    "    \"HPE Data fabric\",\n",
    "    \"C++\",\n",
    "    \"Java\",\n",
    "    \"C#\"\n",
    "  ],\n",
    "  \"spoken languages\": [\n",
    "    \"Arabic\",\n",
    "    \"English\"\n",
    "  ]\n",
    "}\"\"\"\n",
    "f = re.search(r'```\\s*(?:json)?\\s*(.*?)```', t, re.DOTALL).group(1).strip()\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e3bf43-ed94-4b07-840e-a67c3e97e363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
