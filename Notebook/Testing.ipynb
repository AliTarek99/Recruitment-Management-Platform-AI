{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5889f7d-6cf9-494e-830c-4513a17b0c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pdfplumber\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from groq import Groq\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40cfdcd3-52bd-40a2-b0a0-74c98ac5b99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sandy Adel Latef\n",
      "Email : sandyadel877047@gmail.com GitHub : sundy-adel\n",
      "Phone : +201226267470 LinkedIn : sundy-adel\n",
      "Career Objective\n",
      "Master in AI and data science from Ottawa University.\n",
      "I’m very motivated to gain experience and improve myself, as I’m passionate about data fields.\n",
      "Education\n",
      "Ottawa University, Faculty of Engineering, Canada Feb 23 – Jan 24\n",
      "MEng in AI and data science\n",
      "Assiut University, Faculty of Computers and Information, Egypt Aug 18 – Aug 22\n",
      "Bachelor's degree in bioinformatics\n",
      "Overall Grade: 3.48 out of 4.0 - Overall Percentage: 87%\n",
      "Projects\n",
      "• Deep Fake Image Detection – CV Jan 24\n",
      "Tool: Python, CNN, Streamlit, TensorFlow\n",
      "Detect if the image is fake or real by training the model on 140K images\n",
      "• Single Object Detection – CV Nov 23\n",
      "Tool: Python, Yolo\n",
      "Detect object in videos after we split the videos into frames\n",
      "• Predicting Data Exfiltration Via DNS – ML Nov 23\n",
      "Tool: Python, Docker, and Kafka streaming\n",
      "A binary classifier project to predict data exfiltration via DNS\n",
      "Testing the difference between static and dynamic Models using streaming data\n",
      "• Stock Market Prediction – ML Jul 23\n",
      "Tool: Python, Time series data\n",
      "Predict if the stock will be higher or lower in the next day\n",
      "• Heart Disease Prediction – DL Jul 23\n",
      "Tool: Python, ANN\n",
      "Predict the likelihood of heart disease based on input features\n",
      "• Movies Recommender – Chatbot Jun 23\n",
      "Tool: Python, Flask, Dialogflow\n",
      "Chatbot that recommends movies according to your choices\n",
      "• Text Classification & Text Clustering – NLP Jun 23\n",
      "Tool: Python\n",
      "comprising five distinct books from the Gutenberg Books dataset\n",
      "partitioning and predicting which partition belongs to which book• From 2018 to 2022\n",
      "Assiut University’s Hospitals website (Front End)\n",
      "Train ticket reservation system using C++\n",
      "Library management system using Java\n",
      "Picture Viewer using C#\n",
      "Heart disease using Ontology\n",
      "Genetic database pairwise sequence alignment\n",
      "Certifications\n",
      "• Huawei cloud HCDDA Feb 24\n",
      "• Azure Artificial Intelligence fundamental from Microsoft Dec 23\n",
      "• Artificial Intelligence Analyst from IBM Apr 23\n",
      "• Python for Data Science from IBM Apr 23\n",
      "• Big Data Engineer from IBM Mar 23\n",
      "• Predictive Analytics Modeler from IBM Mar 23\n",
      "• IBM SPSS Modeler V18.2.X Essential Feb 23\n",
      "• Assiut University’s Hospitals website development competition Aug 22\n",
      "• Android mobile development course by ITI Aug 21\n",
      "• Android mobile development course by DSC Feb 21\n",
      "Experience & Soft Skills\n",
      "• Click ITS company Jan 24 – Mar 24\n",
      "Data engineer intern\n",
      "• Dale Carnage Course Feb 23 – Apr 23\n",
      "Training to be a good leader and improve communication skills\n",
      "• Orange Telecommunication Company Nov 22 – Jan 23\n",
      "Call center agent at Orange, help customers and handle angry customers\n",
      "• ACM Aug 18 – Aug 22\n",
      "Member at ACM, a community which solve problems through programming\n",
      "• Scout group Aug 12 – Aug 22\n",
      "Leader at the scout group\n",
      "Skills\n",
      "• Programming\n",
      "Python | SQL\n",
      "• Software engineering\n",
      "Data Structure | Relational DB | Problem solving\n",
      "• Data Science\n",
      "Data Analysis | AI | ML | DL | NLP | CV | Statistics | Time Series\n",
      "• Other\n",
      "Git | Githup | tableau | Dataiku | HPE Data fabric\n",
      "Languages\n",
      "Arabic Native language\n",
      "English Very good\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "pdf_text = extract_text_from_pdf(\"F:\\\\GPResources\\\\New CVs\\\\CV Sandy Adel.pdf\")\n",
    "print(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc3bc1e9-e75f-4009-b9fc-40b29cacbb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, I'm trying to figure out how to extract structured information from this resume into JSON format based on the user's instructions. Let me break it down step by step.\n",
      "\n",
      "First, I need to understand the structure they want. The example provided includes sections like contactInformation, education, workExperience, skills, languages, etc. So, my goal is to map each part of the resume text into these corresponding JSON fields.\n",
      "\n",
      "Starting with contact information: The resume starts with the name \"HAGER NASSER ELHALWANY\". Then it lists the location as \"Elsanta, Tanta, Egypt\", a phone number \"+20 109 067 4213\", and an email \"hager51naser@gmail.com\". The GitHub link isn't explicitly mentioned in contact info but is under projects, so I'll exclude that for now.\n",
      "\n",
      "Next, education: There are two educational entries. The first is a diploma in Artificial Intelligence & Machine Learning from Information Technology Institute (ITI), Mansoura, Egypt, spanning October 2021 to June 2022. The second is a Bachelor's degree in Electrical Engineering from Tanta University, October 2017 to August 2021, with a very good grade.\n",
      "\n",
      "Work experience: There are two work experiences. The first is as a Junior Freelance Machine Learning Engineer starting May 2022 to present via Upwork. The second is Content Marketing at FoxTech Media from August 2021 to November 2021 in Tanta, Egypt.\n",
      "\n",
      "Projects: The resume lists two projects. The OLSM System was developed from May 2022 to August 2022 using various tools and technologies. The InferMedica Chatbot was built from March 2021 to June 2021 using NLP techniques and Flask APIs.\n",
      "\n",
      "Skills section is quite extensive. I'll list each skill separately, ensuring they are in the skills array as individual strings.\n",
      "\n",
      "Languages: The resume mentions Arabic as native and English as very good. So, both should be included.\n",
      "\n",
      "I also notice that the GitHub link is under activities, but since it's a contact point, maybe it should go into contactInformation. However, in the initial example, GitHub isn't part of contact info, so I'll stick to excluding it unless instructed otherwise.\n",
      "\n",
      "Now, formatting dates: The user wants standardized formats like \"Month Year - Month Year\". For example, October 2021 – June 2022. Similarly, locations should be \"City, Country\".\n",
      "\n",
      "I need to ensure all fields are clear and concise, no extra info. Also, skills and languages should be in correct formats without any additional descriptions.\n",
      "\n",
      "Finally, I'll structure everything into JSON with proper nesting, ensuring no syntax errors. Each section like education will have its own array of objects, same for work experience and projects.\n",
      "</think>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"contactInformation\": {\n",
      "    \"name\": \"Hager Nasser Elhalwany\",\n",
      "    \"phone\": \"+20 109 067 4213\",\n",
      "    \"email\": \"hager51naser@gmail.com\",\n",
      "    \"location\": \"Elsanta, Tanta, Egypt\"\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"ITI Diploma in Artificial Intelligence & Machine Learning\",\n",
      "      \"university\": \"Information Technology Institute, Mansoura, Egypt\",\n",
      "      \"start Year\": \"2021\",\n",
      "      \"End Year\": \"2022\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Bachelor of Electrical Engineering\",\n",
      "      \"university\": \"Tanta University, Tanta, Egypt\",\n",
      "      \"start Year\": \"2017\",\n",
      "      \"End Year\": \"2021\",\n",
      "      \"grade\": \"Very Good\"\n",
      "    }\n",
      "  ],\n",
      "  \"workExperience\": [\n",
      "    {\n",
      "      \"title\": \"Junior Freelance Machine Learning Engineer\",\n",
      "      \"company\": \"Upwork Platform (Remote)\",\n",
      "      \"start date\": \"May 2022\",\n",
      "      \"end date\": \"Present\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Content Marketing Specialist\",\n",
      "      \"company\": \"FoxTech Media company\",\n",
      "      \"location\": \"Tanta, Egypt\",\n",
      "      \"start date\": \"August 2021\",\n",
      "      \"end date\": \"November 2021\"\n",
      "    }\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"name\": \"OLSM SYSTEM\",\n",
      "      \"description\": \"Application used to Enhance the online learning process.\",\n",
      "      \"duration\": \"May 2022 – August 2022\",\n",
      "      \"technologies\": [\"Python\", \"Flask\", \"Gunicorn\", \"PyMongo\", \"Dash\", \"JavaScript\", \"Google Colab\", \"Amazon EC2 T3 Medium\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"InferMedica Chatbot\",\n",
      "      \"description\": \"QA System For COVID-19 Questions Using NLP Techniques.\",\n",
      "      \"duration\": \"March 2021 – June 2021\",\n",
      "      \"technologies\": [\"Python\", \"Flask\", \"TensorFlow\", \"NLTK\"]\n",
      "    }\n",
      "  ],\n",
      "  \"skills\": [\n",
      "    \"Artificial Intelligence\",\n",
      "    \"Machine Learning\",\n",
      "    \"Python\",\n",
      "    \"R\",\n",
      "    \"TensorFlow\",\n",
      "    \"Keras\",\n",
      "    \"Deep Learning\",\n",
      "    \"NLP\",\n",
      "    \"Natural Language Processing\",\n",
      "    \"Flask\",\n",
      "    \"Django\",\n",
      "    \"SQL\",\n",
      "    \"MongoDB\",\n",
      "    \"Data Analysis\",\n",
      "    \"Data Visualization\",\n",
      "    \"Statistics\",\n",
      "    \"Algorithm Design\"\n",
      "  ],\n",
      "  \"languages\": [\n",
      "    {\n",
      "      \"name\": \"Arabic\",\n",
      "      \"level\": \"Native\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"English\",\n",
      "      \"level\": \"Very Good\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Execution time: 0:02:45.692216\n"
     ]
    }
   ],
   "source": [
    "model = \"deepseek-r1:8b\"\n",
    "prompt = '''You are an AI assistant specialized in extracting structured information from resumes. Given the following resume text, extract key details in exactly this JSON format:\n",
    "\n",
    "---\n",
    "{\n",
    "  \"contactInformation\": {\n",
    "    \"name\": \"Full Name\",\n",
    "    \"phone\": \"Phone Number\",\n",
    "    \"email\": \"Email Address\",\n",
    "    \"location\": \"City, Country\"\n",
    "  },\n",
    "  \"education\": [\n",
    "    {\n",
    "      \"degree\": \"Degree Name\",\n",
    "      \"university\": \"University Name\",\n",
    "      \"start Year\": \"Start Year\"\n",
    "      \"End Year\": \"End Year\"\n",
    "      \"grade\": \"provided grade\"\n",
    "    }\n",
    "  ],\n",
    "  \"workExperience\": [\n",
    "    {\n",
    "      \"title\": \"Job Title\",\n",
    "      \"company\": \"Company Name\",\n",
    "      \"start date\": \"Month/Year\"\n",
    "      \"end date\": \"Month/Year\"\n",
    "      \"end date\"\n",
    "    }\n",
    "  ],\n",
    "  \"skills\": [\n",
    "    \"Skill 1\",\n",
    "    \"Skill 2\",\n",
    "    \"Skill 3\"\n",
    "  ],\n",
    "  \"languages\": [\n",
    "    \"Language 1\",\n",
    "    \"Language 2\"\n",
    "  ]\n",
    "}\n",
    "---\n",
    "\n",
    "Instructions:\n",
    "1. Maintain the exact JSON structure with correct nesting, this is a top priority.\n",
    "2. Extract all available information while preserving accuracy.\n",
    "3. Use standardized formats for dates (`Month Year - Month Year`) and location (`City, Country`).\n",
    "4. Ensure all extracted fields are clear and concise.\n",
    "5. In the \"languages\" section, write only the language name.\n",
    "6. In the \"skills\" section, write individual skills separated by commas.\n",
    "\n",
    "Now, extract the information from this resume:\n",
    "\n",
    "---\\n''' + pdf_text + '''\\n ---'''\n",
    "start = datetime.now()\n",
    "response = ollama.chat(model = model, messages= [{'role':'user', 'content': prompt}],keep_alive=\"20m\")\n",
    "end = datetime.now()\n",
    "\n",
    "ollamaResponse = response['message']['content']\n",
    "\n",
    "print(ollamaResponse)\n",
    "print(f\"Execution time: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20ef9c69-b004-44bc-acb3-0dc12994d56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, I need to extract structured information from this resume and format it into JSON as per the given instructions. Let me start by reading through the resume carefully.\n",
      "\n",
      "First, the contact information is at the top. The name is Hager Nasser Elhalwany. The phone number is +20 109 067 4213. The email is hager51naser@gmail.com. The location is listed as Elsanta, Tanta, Egypt. So I'll structure that under \"contactInformation\".\n",
      "\n",
      "Next, looking at the projects section. There are two projects mentioned: OLSM SYSTEM and InferMedica Chatbot. For each project, I need to extract the title, dates, and descriptions.\n",
      "\n",
      "OLS M SYSTEM was active from May 2022 to August 2022. The technologies used include Python, Flask, Gunicorn, PyMongo, Dash, JavaScript, Google Colab, and Amazon EC2 T3 Medium. I'll list these under \"technologies\" in a comma-separated string.\n",
      "\n",
      "InferMedica Chatbot ran from March 2021 to June 2021. The techniques used are TF-IDF, LSA, Glove for information retrieval, and neural models using seq2seq with Flask APIs. I'll include the key techniques as bullet points in \"description\".\n",
      "\n",
      "Moving on to work experience, there are two roles. The first is as a Junior Freelancer Machine Learning Engineer from May 2022 to present at Upwork, remote work. The second role is Content Marketing at FoxTech Media from August 2021 to November 2021 in Tanta, Egypt.\n",
      "\n",
      "For each job, I'll include the title, company, location (if applicable), start and end dates, and a brief description of responsibilities.\n",
      "\n",
      "Education comes next with two entries: an ITI diploma in AI and ML from Information Technology Institute, Mansoura, from October 2021 to June 2022. Also, a Bachelor of Electrical Engineering at Tanta University from October 2017 to August 2021. Grades are \"very good\" for the bachelor's.\n",
      "\n",
      "Courser courses include Data Analysis Professional Nanodegree (Future Work is Digital) from January to March 2023 and Machine Learning by Andrew Ng from November 2020 to January 2021.\n",
      "\n",
      "Skills are listed as Python, C++, HTML & CSS, Plotly, Dash, Matplotlib, seaborn, SQL, MongoDB, PowerBI, NumPy, Pandas, Scikit-learn, PyTorch, TensorFlow, Keras, Apache Spark, Deep learning with CNNs and ResNet, Microsoft tools like Excel, Word, PowerPoint, Web Scraping with Selenium, Beautiful Soup, Scrapy, Data structures and algorithms, data analytics, mathematics, soft skills like teamwork and communication.\n",
      "\n",
      "Languages are Arabic (native) and English (very good).\n",
      "\n",
      "I need to make sure all the dates are in Month Year - Month Year format. Locations should be City, Country. Skills and languages should follow the specified formatting with commas separating individual skills and only the language names in languages.\n",
      "\n",
      "Let me structure this JSON correctly without any markdown.\n",
      "</think>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"contactInformation\": {\n",
      "    \"name\": \"Hager Nasser Elhalwany\",\n",
      "    \"phone\": \"+20 109 067 4213\",\n",
      "    \"email\": \"hager51naser@gmail.com\",\n",
      "    \"location\": \"Elsanta, Tanta, Egypt\"\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"ITI Diploma in Artificial Intelligence & Machine Learning\",\n",
      "      \"university\": \"Information Technology Institute, Mansoura, Egypt\",\n",
      "      \"start Year\": \"2021\",\n",
      "      \"End Year\": \"2022\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Bachelor of Electrical Engineering\",\n",
      "      \"university\": \"Faculty of Engineering, Tanta University, Tanta, Egypt\",\n",
      "      \"start Year\": \"2017\",\n",
      "      \"End Year\": \"2021\",\n",
      "      \"grade\": \"VERY GOOD\"\n",
      "    }\n",
      "  ],\n",
      "  \"workExperience\": [\n",
      "    {\n",
      "      \"title\": \"Junior Freelancer Machine Learning Engineer\",\n",
      "      \"company\": \"Upwork Platform\",\n",
      "      \"location\": \"Remote Work\",\n",
      "      \"start date\": \"May/2022\",\n",
      "      \"end date\": \"Present\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Content Marketing\",\n",
      "      \"company\": \"FoxTech Media company\",\n",
      "      \"location\": \"Tanta, Egypt\",\n",
      "      \"start date\": \"Aug/2021\",\n",
      "      \"end date\": \"Nov/2021\"\n",
      "    }\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"title\": \"OLSM SYSTEM\",\n",
      "      \"description\": \"Application used to Enhance the online learning process.\",\n",
      "      \"dates\": \"May 2022 – Aug 2022\",\n",
      "      \"technologies\": \"Python, Flask, Gunicorn, PyMongo, Dash, JavaScript, Google Colab, Amazon EC2 T3 Medium\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"InferMedica Chatbot\",\n",
      "      \"description\": \"Information retrieval techniques: TF-IDF, LSA, Glove; Neural models: seq2seq with Flask APIs.\",\n",
      "      \"dates\": \"March 2021 – June 2021\"\n",
      "    }\n",
      "  ],\n",
      "  \"courses\": [\n",
      "    {\n",
      "      \"title\": \"Data Analysis Professional Nanodegree\",\n",
      "      \"provider\": \"Future Work is Digital\",\n",
      "      \"dates\": \"Jan/2023 – Mar/2023\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Machine Learning\",\n",
      "      \"instructor\": \"Andrew Ng\",\n",
      "      \"dates\": \"Nov/2020 – Jan/2021\"\n",
      "    }\n",
      "  ],\n",
      "  \"skills\": [\n",
      "    \"Python, C++, HTML & CSS, Plotly, Dash, Matplotlib, seaborn, SQL, MongoDB, PowerBI, NumPy, Pandas, Scikit-learn, PyTorch, TensorFlow, Keras, Apache Spark, Deep learning with CNNs and ResNet, Microsoft tools (Excel, Word, PowerPoint), Web Scraping (Selenium, Beautiful Soup, Scrapy), Data structures and algorithms, Data analytics, Mathematics, Soft skills (Teamwork, Communication)\",\n",
      "    \"Arabic: native. English: Very good.\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Execution time: 0:03:30.396452\n"
     ]
    }
   ],
   "source": [
    "model = \"llama3.2\"\n",
    "prompt = '''You are an AI assistant specialized in extracting structured information from resumes. Given the following resume text, extract key details in exactly this JSON format. Here's an example:\n",
    "\n",
    "---\n",
    "{\n",
    "  \"contactInformation\": {\n",
    "    \"name\": \"Ahmed Abdelghani\",\n",
    "    \"phone\": \"+201014173523\",\n",
    "    \"email\": \"ahmedabdelghani404@gmail.com\",\n",
    "    \"location\": \"Cairo, Egypt\"\n",
    "  },\n",
    "  \"education\": [\n",
    "    {\n",
    "      \"degree\": \"Bachelor of Computer Science\",\n",
    "      \"university\": \"Suez University, Faculty of Computers and Information\",\n",
    "      \"start Year\": \"2018\"\n",
    "      \"End Year\": \"2022\"\n",
    "      \"grade\": \"3.01\"\n",
    "    }\n",
    "  ],\n",
    "  \"workExperience\": [\n",
    "    {\n",
    "      \"title\": \"Financial Analyst\",\n",
    "      \"company\": \"AIESEC\",\n",
    "      \"start date\": \"August/2022\"\n",
    "      \"end date\": \"Present\"\n",
    "    }\n",
    "  ],\n",
    "  \"skills\": [\n",
    "    \"Python\", \"SQL\", \"NoSQL\", \"JavaScript\",\"Data Warehousing\"\n",
    "  ],\n",
    "  \"languages\": [\n",
    "    \"Arabic\",\n",
    "    \"English\"\n",
    "  ]\n",
    "}\n",
    "---\n",
    "\n",
    "Instructions:\n",
    "1. Maintain the exact JSON structure with correct nesting, this is a top priority.\n",
    "2. Extract all available information while preserving accuracy.\n",
    "3. Use standardized formats for dates (`Month Year - Month Year`) and location (`City, Country`).\n",
    "4. Ensure all extracted fields are clear and concise.\n",
    "5. Write only the language name in the \"languages\" section.\n",
    "6. Write individual skills separated by commas in the \"skills\" section.\n",
    "7. The output should be the JSON code only and nothing else.\n",
    "\n",
    "Now, extract the information from this resume:\n",
    "\n",
    "---\\n''' + pdf_text + '''\\n ---'''\n",
    "start = datetime.now()\n",
    "response = ollama.chat(model = model, messages= [{'role':'user', 'content': prompt}],keep_alive=\"20m\")\n",
    "end = datetime.now()\n",
    "\n",
    "ollamaResponse = response['message']['content']\n",
    "\n",
    "print(ollamaResponse)\n",
    "print(f\"Execution time: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ba6e2c-0151-4f41-8bf0-d572027fd0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, I need to extract the education information from this resume and format it into JSON as specified. Let me start by reading through the resume carefully.\n",
      "\n",
      "First, I'll look for the section labeled \"EDUCATION\". Scanning through, I see that under \"WORK EXPERIENCE\" there's a mention of \"ITI Diploma in Artificial Intelligence & Machine Learning\" awarded by the Information Technology Institute in Mansoura, Egypt. The dates are OCT 2021 – JUN 2022.\n",
      "\n",
      "Next, it mentions a 9-month program powered by EPITA, which is the French Graduate School of Computer Science and Advanced Technology in Paris, France, but there's no specific degree mentioned here. So I'll note that as another education entry without a degree specified.\n",
      "\n",
      "Then, there's a Bachelor of Electrical Engineering with a Control and Automatic Control Department at Tanta University, Egypt, from OCT 2017 – AUG 2021, with a grade of VERY GOOD.\n",
      "\n",
      "I need to structure each education entry correctly. Each should include degree, university, start year, end year, and grade where applicable. For the EPITA program, since there's no degree specified, I'll leave that field blank or set it to null if allowed by the JSON schema.\n",
      "\n",
      "I also notice a course mentioned: Data Analysis Professional Nanodegree from Future Work is Digital on Udacity, but this seems more like a professional development course rather than an academic education. It might not be necessary unless the resume explicitly lists it under education, which it doesn't. So I'll focus only on the formal education entries.\n",
      "\n",
      "Putting it all together, I'll create an array of objects within the \"education\" key in JSON format, ensuring correct nesting and field inclusion as per the example provided.\n",
      "</think>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"ITI Diploma in Artificial Intelligence & Machine Learning\",\n",
      "      \"university\": \"Information Technology Institute, Mansoura, Egypt.\",\n",
      "      \"start Year\": \"OCT 2021\",\n",
      "      \"end Year\": \"JUN 2022\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"\",\n",
      "      \"university\": \"EPITA, Paris, France\",\n",
      "      \"start Year\": \"\",\n",
      "      \"end Year\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Bachelor of Electrical Engineering\",\n",
      "      \"university\": \"Computer and Automatic Control Department, Faculty of Engineering, Tanta University, Tanta, Egypt.\",\n",
      "      \"start Year\": \"OCT 2017\",\n",
      "      \"end Year\": \"AUG 2021\",\n",
      "      \"grade\": \"VERY GOOD\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Execution time: 0:01:13.457059\n"
     ]
    }
   ],
   "source": [
    "model = \"deepseek-r1:8b\"\n",
    "prompt = '''You are an AI assistant specialized in extracting structured information from resumes. Given the following resume text, extract the education part in exactly this JSON format. Here's an example:\n",
    "\n",
    "---\n",
    "{\n",
    "  \"education\": [\n",
    "    {\n",
    "      \"degree\": \"Degree Name\",\n",
    "      \"university\": \"University Name\",\n",
    "      \"start Year\": \"Start Year\"\n",
    "      \"End Year\": \"End Year\"\n",
    "      \"grade\": \"Provided grade\"\n",
    "    }]\n",
    "}\n",
    "---\n",
    "\n",
    "Instructions:\n",
    "1. Maintain the exact JSON structure with correct nesting, this is a top priority.\n",
    "2. Extract all available information while preserving accuracy.\n",
    "4. Ensure all extracted fields are clear and concise.\n",
    "5. The output should be the JSON code only and nothing else.\n",
    "\n",
    "Now, extract the information from this resume:\n",
    "\n",
    "---\\n''' + pdf_text + '''\\n ---'''\n",
    "start = datetime.now()\n",
    "response = ollama.chat(model = model, messages= [{'role':'user', 'content': prompt}],keep_alive=\"20m\")\n",
    "end = datetime.now()\n",
    "\n",
    "ollamaResponse = response['message']['content']\n",
    "\n",
    "print(ollamaResponse)\n",
    "print(f\"Execution time: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f2791c9-a4f9-438b-9723-940d19a7cc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"contactInformation\": {\n",
      "    \"name\": \"HAGER NASSER ELHALWANY\",\n",
      "    \"phone\": \"+20 109 067 4213\",\n",
      "    \"email\": \"hager51naser@gmail.com\",\n",
      "    \"location\": \"Tanta, Egypt\"\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"ITI Diploma in Artificial Intelligence & Machine Learning\",\n",
      "      \"university\": \"Information Technology Institute, Mansoura, Egypt\",\n",
      "      \"start Year\": \"OCT 2021\",\n",
      "      \"End Year\": \"JUN 2022\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"9-MONTH PROGRAM, POWERED BY FRENCH GRADUATE SCHOOL OF COMPUTER SCIENCE AND ADVANCED TECHNOLOGY (EPITA), PARIS, FRANCE.\",\n",
      "      \"university\": \"Information Technology Institute, Mansoura, Egypt\",\n",
      "      \"start Year\": \"OCT 2021\",\n",
      "      \"End Year\": \"JUN 2022\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Bachelor of Electrical Engineering Computer and Automatic Control Department\",\n",
      "      \"university\": \"Faculty of Engineering, Tanta University, Tanta, Egypt\",\n",
      "      \"start Year\": \"OCT 2017\",\n",
      "      \"End Year\": \"AUG 2021\",\n",
      "      \"grade\": \"VERY GOOD\"\n",
      "    }\n",
      "  ],\n",
      "  \"workExperience\": [\n",
      "    {\n",
      "      \"title\": \"Junior Freelancer Machine Learning Engineer\",\n",
      "      \"company\": \"Remote Work | Upwork Platform\",\n",
      "      \"start date\": \"MAY 2022\",\n",
      "      \"end date\": \"PRESENT\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Content Marketing\",\n",
      "      \"company\": \"FoxTech Media company, Tanta, Egypt\",\n",
      "      \"start date\": \"AUG 2021\",\n",
      "      \"end date\": \"NOV 2021\"\n",
      "    }\n",
      "  ],\n",
      "  \"skills\": [\n",
      "    \"Python\", \n",
      "    \"C++\", \n",
      "    \"HTML & CSS\", \n",
      "    \"Data visualization (Plotly, Dash, Matplotlib, seaborn)\", \n",
      "    \"SQL\", \n",
      "    \"MongoDB NoSQL\",\n",
      "    \"Machine learning (NumPy, Pandas, Sklearn, PyTorch, TensorFlow, Keras)\",\n",
      "    \"Deep learning (Neural Networks, Natural Language Processing, Seq2Seq model, CNNs, RESNET)\",\n",
      "    \"Data structures and Algorithms\",\n",
      "    \"Data analytics & Mathematics\",\n",
      "    \"Cloud computing\",\n",
      "    \"Apache Spark\",\n",
      "    \"Microsoft tools (Excel, Word, PowerPoint)\",\n",
      "    \"Web Scraping (selenium, Beautiful Soup, Scrapy)\",\n",
      "    \"Soft Skills (Self-study, Teamwork, Communication skills, Presentation skills)\"\n",
      "  ],\n",
      "  \"languages\": [\n",
      "    \"Arabic\", \n",
      "    \"English\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Execution time: 0:05:06.144187\n"
     ]
    }
   ],
   "source": [
    "model = \"phi4\"\n",
    "prompt = '''You are an AI assistant specialized in extracting structured information from resumes. Given the following resume text, extract key details in exactly this JSON format:\n",
    "\n",
    "---\n",
    "{\n",
    "  \"contactInformation\": {\n",
    "    \"name\": \"Full Name\",\n",
    "    \"phone\": \"Phone Number\",\n",
    "    \"email\": \"Email Address\",\n",
    "    \"location\": \"City, Country\"\n",
    "  },\n",
    "  \"education\": [\n",
    "    {\n",
    "      \"degree\": \"Degree Name\",\n",
    "      \"university\": \"University Name\",\n",
    "      \"start Year\": \"Start Year\"\n",
    "      \"End Year\": \"End Year\"\n",
    "      \"grade\": \"provided grade\"\n",
    "    }\n",
    "  ],\n",
    "  \"workExperience\": [\n",
    "    {\n",
    "      \"title\": \"Job Title\",\n",
    "      \"company\": \"Company Name\",\n",
    "      \"start date\": \"Month/Year\"\n",
    "      \"end date\": \"Month/Year\"\n",
    "      \"end date\"\n",
    "    }\n",
    "  ],\n",
    "  \"skills\": [\n",
    "    \"Skill 1\",\n",
    "    \"Skill 2\",\n",
    "    \"Skill 3\"\n",
    "  ],\n",
    "  \"languages\": [\n",
    "    \"Language 1\",\n",
    "    \"Language 2\"\n",
    "  ]\n",
    "}\n",
    "---\n",
    "\n",
    "Instructions:\n",
    "1. Maintain the exact JSON structure with correct nesting, this is a top priority.\n",
    "2. Extract all available information while preserving accuracy.\n",
    "3. Use standardized formats for dates (`Month Year - Month Year`) and location (`City, Country`).\n",
    "4. Ensure all extracted fields are clear and concise.\n",
    "5. In the \"languages\" section, write only the language name.\n",
    "6. In the \"skills\" section, write individual skills separated by commas.\n",
    "\n",
    "Now, extract the information from this resume:\n",
    "\n",
    "---\\n''' + pdf_text + '''\\n ---'''\n",
    "start = datetime.now()\n",
    "response = ollama.chat(model = model, messages= [{'role':'user', 'content': prompt}],keep_alive=\"20m\")\n",
    "end = datetime.now()\n",
    "\n",
    "ollamaResponse = response['message']['content']\n",
    "\n",
    "print(ollamaResponse)\n",
    "print(f\"Execution time: {end - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6531c0-c120-4c68-ab8d-00869443247a",
   "metadata": {},
   "source": [
    "<font size=\"6\">Groq API</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df0ef966-1135-494a-be6c-ee92accad510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "{\n",
      "  \"contactInformation\": {\n",
      "    \"name\": \"Sandy Adel Latef\",\n",
      "    \"phone\": \"+201226267470\",\n",
      "    \"email\": \"sandyadel877047@gmail.com\",\n",
      "    \"location\": \"Canada\"\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"MEng in AI and data science\",\n",
      "      \"university\": \"Ottawa University\",\n",
      "      \"faculty\": \"Faculty of Engineering\",\n",
      "      \"start Year\": \"Feb 23\",\n",
      "      \"End Year\": \"Jan 24\",\n",
      "      \"grade\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Bachelor's degree in bioinformatics\",\n",
      "      \"university\": \"Assiut University\",\n",
      "      \"faculty\": \"Faculty of Computers and Information\",\n",
      "      \"start Year\": \"Aug 18\",\n",
      "      \"End Year\": \"Aug 22\",\n",
      "      \"grade\": \"3.48\"\n",
      "    }\n",
      "  ],\n",
      "  \"workExperience\": [\n",
      "    {\n",
      "      \"title\": \"Data engineer intern\",\n",
      "      \"company\": \"Click ITS company\",\n",
      "      \"start date\": \"Jan 24\",\n",
      "      \"end date\": \"Mar 24\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Call center agent\",\n",
      "      \"company\": \"Orange Telecommunication Company\",\n",
      "      \"start date\": \"Nov 22\",\n",
      "      \"end date\": \"Jan 23\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Member\",\n",
      "      \"company\": \"ACM\",\n",
      "      \"start date\": \"Aug 18\",\n",
      "      \"end date\": \"Aug 22\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Leader\",\n",
      "      \"company\": \"Scout group\",\n",
      "      \"start date\": \"Aug 12\",\n",
      "      \"end date\": \"Aug 22\"\n",
      "    }\n",
      "  ],\n",
      "  \"skills\": [\n",
      "    \"Python\",\n",
      "    \"SQL\",\n",
      "    \"Data Structure\",\n",
      "    \"Relational DB\",\n",
      "    \"Problem solving\",\n",
      "    \"Data Analysis\",\n",
      "    \"Artificial Intelligence\",\n",
      "    \"Machine Learning\",\n",
      "    \"Deep Learning\",\n",
      "    \"Natural Language Processing\",\n",
      "    \"Computer Vision\",\n",
      "    \"Statistics\",\n",
      "    \"Time Series\",\n",
      "    \"Git\",\n",
      "    \"GitHub\",\n",
      "    \"Tableau\",\n",
      "    \"Dataiku\",\n",
      "    \"HPE Data fabric\",\n",
      "    \"C++\",\n",
      "    \"Java\",\n",
      "    \"C#\",\n",
      "    \"Ontology\",\n",
      "    \"Genetic database pairwise sequence alignment\"\n",
      "  ],\n",
      "  \"spoken languages\": [\n",
      "    \"Arabic\",\n",
      "    \"English\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = '''You are an AI assistant specialized in extracting structured information from resumes. Given the following resume text, extract key details in exactly this JSON format. Here's an example:\n",
    "\n",
    "---\n",
    "{\n",
    "  \"contactInformation\": {\n",
    "    \"name\": \"Full Name\",\n",
    "    \"phone\": \"Phone Number\",\n",
    "    \"email\": \"Email Address\",\n",
    "    \"location\": \"City, Country\"\n",
    "  },\n",
    "  \"education\": [\n",
    "    {\n",
    "      \"degree\": \"Degree Name\",\n",
    "      \"university\": \"University Name\",\n",
    "      \"faculty\": \"Faculty Name\",\n",
    "      \"start Year\": \"Start Year\",\n",
    "      \"End Year\": \"End Year\",\n",
    "      \"grade\": \"provided grade\"\n",
    "    }\n",
    "  ],\n",
    "  \"workExperience\": [\n",
    "    {\n",
    "      \"title\": \"Job Title\",\n",
    "      \"company\": \"Company Name\",\n",
    "      \"start date\": \"Month Year\",\n",
    "      \"end date\": \"Month Year\"\n",
    "    }\n",
    "  ],\n",
    "  \"skills\": [\n",
    "    \"Skill 1\",\n",
    "    \"Skill 2\",\n",
    "    \"Skill 3\"\n",
    "  ],\n",
    "  \"spoken languages\": [\n",
    "    \"Language 1\",\n",
    "    \"Language 2\"\n",
    "  ]\n",
    "}\n",
    "---\n",
    "\n",
    "Instructions:\n",
    "1. Maintain the exact JSON structure with correct nesting, this is a top priority.\n",
    "2. Extract all available information while preserving accuracy.\n",
    "3. Use standardized formats for dates (`Month Year - Month Year`) and location (`City, Country`).\n",
    "4. Ensure all extracted fields are clear and concise.\n",
    "5. Write only the language name in the \"languages\" section.\n",
    "6. Write individual skills in a list of skills in the \"skills\" section.\n",
    "7. Write the GPA number only in the \"grade\" section of education, if GPA is not provided try searching for percentage, else leave blank.\n",
    "8. If a field is not found leave blank.\n",
    "9. The output should be the JSON code only and nothing else.\n",
    "10. Search skills in all fields in the CV.\n",
    "11. Expand abbreviations (if found) into their full form where applicable (e.g., \"ML\" to \"Machine Learning\", \"NLP\" to \"Natural Language Processing\").\n",
    "\n",
    "Now, extract the information from this resume:\n",
    "\n",
    "---\\n''' + pdf_text + '''\\n ---'''\n",
    "\n",
    "client = Groq(\n",
    "\n",
    "    api_key= \"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\",\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "CV_query = client.chat.completions.create(\n",
    "\n",
    "    messages=[\n",
    "\n",
    "        {\n",
    "\n",
    "            \"role\": \"user\",\n",
    "\n",
    "            \"content\": prompt,\n",
    "\n",
    "        }\n",
    "\n",
    "    ],\n",
    "\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "print(CV_query.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60974608-6d2e-406b-b704-c82baf048215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"skills\": [\n",
      "    \"Excel\",\n",
      "    \"Google Sheets\",\n",
      "    \"Data Analysis\",\n",
      "    \"Data Visualization\",\n",
      "    \"Pivot Tables\",\n",
      "    \"Web Scraping\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "job_desc = '''\n",
    "Who We Are:\n",
    "\n",
    "\n",
    "Rehlat.com is an award-winning Online Travel Agency (OTA), leading the GCC market with a presence in the Middle East, North Africa, and Europe across 9+ countries.\n",
    "\n",
    "\n",
    "Hiring: Yield & Revenue Analyst\n",
    "\n",
    "\n",
    "Are you passionate about data, pricing strategies, and market trends? Do you enjoy using analytics to drive business decisions? If so, we’re looking for a Yield & Revenue Analyst to join our team!\n",
    "\n",
    "\n",
    "About the Role:\n",
    "\n",
    "\n",
    "As a Yield & Revenue Analyst, you will play a crucial role in ensuring our company maintains a competitive edge in the market. You’ll be responsible for monitoring pricing strategies, analyzing competitor trends, and providing actionable insights to optimize revenue.\n",
    "\n",
    "\n",
    "Key Responsibilities:\n",
    "\n",
    "\n",
    "🔹 Market Intelligence & Web Scraping: Conduct daily/weekly data collection from competitor websites to track pricing, promotions, and trends.\n",
    "\n",
    "🔹 Pricing Analysis: Identify pricing discrepancies, ensuring our offerings remain competitive and aligned with market demand.\n",
    "\n",
    "🔹 Data-Driven Decision Making: Generate detailed pricing reports that highlight trends, opportunities, and the impact of pricing changes.\n",
    "\n",
    "🔹 Revenue Optimization: Provide insights to improve pricing strategies, online sales performance, and promotional planning.\n",
    "\n",
    "🔹 Yield Management Systems: Assist in the development and maintenance of yield management tools to enhance decision-making.\n",
    "\n",
    "\n",
    "What We're Looking For:\n",
    "\n",
    "\n",
    "✔️ Education: Bachelor's degree from a reputable institution.\n",
    "\n",
    "✔️ Languages: Fluent in English & Arabic (spoken & written).\n",
    "\n",
    "✔️ Experience: 0 to 2 years in a similar role (fresh graduates are welcome!).\n",
    "\n",
    "✔️ Technical Skills:\n",
    "\n",
    "    Strong data analysis and interpretation abilities.\n",
    "    Proficiency in Excel/Google Sheets (pivot tables, data visualization, reporting).\n",
    "    Ability to analyze large datasets and extract meaningful insights.\n",
    "    ✔️ Analytical Mindset: Strong problem-solving skills and keen attention to detail.\n",
    "\n",
    "\n",
    "\n",
    "Why Join Us?\n",
    "\n",
    "\n",
    "✅ Gain hands-on experience in revenue management and pricing analytics.\n",
    "\n",
    "✅ Be part of a fast-paced, data-driven environment where your insights make an impact.\n",
    "\n",
    "✅ Grow within a team that values innovation and continuous learning.\n",
    "\n",
    "\n",
    "📩 Ready to take the next step? Apply now and be part of a team shaping the future of revenue optimization!\n",
    "\n",
    "'''\n",
    "\n",
    "prompt = '''You are an AI assistant that extracts required skills from job descriptions.  \n",
    "\n",
    "Given the following job description, extract only the relevant **technical and domain-specific skills** explicitly mentioned in the text, including specific software, tools, technologies, and platforms.  \n",
    "\n",
    "Return the result in **exactly** the following JSON format:  \n",
    "\n",
    "```json\n",
    "{\n",
    "  \"skills\": [\n",
    "    \"Skill 1\",\n",
    "    \"Skill 2\",\n",
    "    \"Skill 3\"\n",
    "  ]\n",
    "}```\n",
    "\n",
    "Rules to Follow:\n",
    "1. Only include explicitly mentioned skills (e.g., \"Python\", \"Machine Learning\", \"SQL\").\n",
    "2. Exclude soft skills (e.g., \"communication\", \"teamwork\", \"problem-solving\").\n",
    "3. Do not include job titles or general terms (e.g., \"Software Engineer\", \"experience in AI\").\n",
    "4. Make sure to check all the qualifications.\n",
    "5. Follow the exact JSON structure—do not add extra fields or explanations.\n",
    "6. The output should be the JSON code only and nothing else, don't add JSON in the beginning.\n",
    "7. Expand abbreviations (if found) into their full form where applicable (e.g., \"ML\" to \"Machine Learning\", \"NLP\" to \"Natural Language Processing\").\n",
    "\n",
    "Job Description: \\n''' + job_desc\n",
    "\n",
    "\n",
    "Job_query = client.chat.completions.create(\n",
    "\n",
    "    messages=[\n",
    "\n",
    "        {\n",
    "\n",
    "            \"role\": \"user\",\n",
    "\n",
    "            \"content\": prompt,\n",
    "\n",
    "        }\n",
    "\n",
    "    ],\n",
    "\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "\n",
    ")\n",
    "\n",
    "print(Job_query.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b538d236-a78d-4864-90ce-dd4ede5cf6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################### CV ###########################\n",
      "{\n",
      "  \"contactInformation\": {\n",
      "    \"name\": \"Sandy Adel Latef\",\n",
      "    \"phone\": \"+201226267470\",\n",
      "    \"email\": \"sandyadel877047@gmail.com\",\n",
      "    \"location\": \"Canada\"\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"MEng in AI and data science\",\n",
      "      \"university\": \"Ottawa University\",\n",
      "      \"faculty\": \"Faculty of Engineering\",\n",
      "      \"start Year\": \"Feb 23\",\n",
      "      \"End Year\": \"Jan 24\",\n",
      "      \"grade\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Bachelor's degree in bioinformatics\",\n",
      "      \"university\": \"Assiut University\",\n",
      "      \"faculty\": \"Faculty of Computers and Information\",\n",
      "      \"start Year\": \"Aug 18\",\n",
      "      \"End Year\": \"Aug 22\",\n",
      "      \"grade\": \"3.48\"\n",
      "    }\n",
      "  ],\n",
      "  \"workExperience\": [\n",
      "    {\n",
      "      \"title\": \"Data engineer intern\",\n",
      "      \"company\": \"Click ITS company\",\n",
      "      \"start date\": \"Jan 24\",\n",
      "      \"end date\": \"Mar 24\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Call center agent\",\n",
      "      \"company\": \"Orange Telecommunication Company\",\n",
      "      \"start date\": \"Nov 22\",\n",
      "      \"end date\": \"Jan 23\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Member\",\n",
      "      \"company\": \"ACM\",\n",
      "      \"start date\": \"Aug 18\",\n",
      "      \"end date\": \"Aug 22\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Leader\",\n",
      "      \"company\": \"Scout group\",\n",
      "      \"start date\": \"Aug 12\",\n",
      "      \"end date\": \"Aug 22\"\n",
      "    }\n",
      "  ],\n",
      "  \"skills\": [\n",
      "    \"Python\",\n",
      "    \"SQL\",\n",
      "    \"Data Structure\",\n",
      "    \"Relational DB\",\n",
      "    \"Problem solving\",\n",
      "    \"Data Analysis\",\n",
      "    \"Artificial Intelligence\",\n",
      "    \"Machine Learning\",\n",
      "    \"Deep Learning\",\n",
      "    \"Natural Language Processing\",\n",
      "    \"Computer Vision\",\n",
      "    \"Statistics\",\n",
      "    \"Time Series\",\n",
      "    \"Git\",\n",
      "    \"GitHub\",\n",
      "    \"Tableau\",\n",
      "    \"Dataiku\",\n",
      "    \"HPE Data fabric\",\n",
      "    \"C++\",\n",
      "    \"Java\",\n",
      "    \"C#\",\n",
      "    \"Ontology\",\n",
      "    \"Genetic database pairwise sequence alignment\"\n",
      "  ],\n",
      "  \"spoken languages\": [\n",
      "    \"Arabic\",\n",
      "    \"English\"\n",
      "  ]\n",
      "}\n",
      "########################### JOB ###########################\n",
      "{\n",
      "  \"skills\": [\n",
      "    \"Excel\",\n",
      "    \"Google Sheets\",\n",
      "    \"Data Analysis\",\n",
      "    \"Data Visualization\",\n",
      "    \"Pivot Tables\",\n",
      "    \"Web Scraping\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "CV_response = CV_query.choices[0].message.content\n",
    "Job_response = Job_query.choices[0].message.content\n",
    "\n",
    "CV = re.search(r'```(.*?)```', CV_response, re.DOTALL)\n",
    "#Job = re.search(r'```(.*?)```', Job_response, re.DOTALL)\n",
    "\n",
    "if CV:\n",
    "    extracted_CV = CV.group(1).strip()\n",
    "# if Job:\n",
    "#     extracted_Job = Job.group(1).strip()\n",
    "\n",
    "extracted_Job = Job_response.strip()   \n",
    "\n",
    "print(\"########################### CV ###########################\")\n",
    "print(extracted_CV)\n",
    "print(\"########################### JOB ###########################\")\n",
    "print(extracted_Job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73ee6fab-94dd-48df-89fa-6cd7da1d8263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contactInformation': {'name': 'Sandy Adel Latef', 'phone': '+201226267470', 'email': 'sandyadel877047@gmail.com', 'location': 'Canada'}, 'education': [{'degree': 'MEng in AI and data science', 'university': 'Ottawa University', 'faculty': 'Faculty of Engineering', 'start Year': 'Feb 23', 'End Year': 'Jan 24', 'grade': ''}, {'degree': \"Bachelor's degree in bioinformatics\", 'university': 'Assiut University', 'faculty': 'Faculty of Computers and Information', 'start Year': 'Aug 18', 'End Year': 'Aug 22', 'grade': '3.48'}], 'workExperience': [{'title': 'Data engineer intern', 'company': 'Click ITS company', 'start date': 'Jan 24', 'end date': 'Mar 24'}, {'title': 'Call center agent', 'company': 'Orange Telecommunication Company', 'start date': 'Nov 22', 'end date': 'Jan 23'}, {'title': 'Member', 'company': 'ACM', 'start date': 'Aug 18', 'end date': 'Aug 22'}, {'title': 'Leader', 'company': 'Scout group', 'start date': 'Aug 12', 'end date': 'Aug 22'}], 'skills': ['Python', 'SQL', 'Data Structure', 'Relational DB', 'Problem solving', 'Data Analysis', 'Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Computer Vision', 'Statistics', 'Time Series', 'Git', 'GitHub', 'Tableau', 'Dataiku', 'HPE Data fabric', 'C++', 'Java', 'C#', 'Ontology', 'Genetic database pairwise sequence alignment'], 'spoken languages': ['Arabic', 'English']}\n",
      "{'skills': ['Excel', 'Google Sheets', 'Data Analysis', 'Data Visualization', 'Pivot Tables', 'Web Scraping']}\n"
     ]
    }
   ],
   "source": [
    "CV_dict = json.loads(extracted_CV)  # Convert to Python dictionary\n",
    "Job_dict = json.loads(extracted_Job)  # Convert to Python dictionary\n",
    "print(CV_dict)\n",
    "print(Job_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ac1a47-7c22-41c5-9603-f0f31b2e2884",
   "metadata": {},
   "source": [
    "<font size=\"6\">Embeddings</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b15c2e7-6735-41e3-8fa9-1a9126914179",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5560d9ed-ef88-4eb7-a8ef-2ad18ef3c4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "workExperience = [\n",
    "    {\n",
    "      \"company_name\": \"Click ITS company\",\n",
    "      \"start_date\": \"Jan 24\",\n",
    "      \"end_date\": \"Mar 24\",\n",
    "      \"description\": '''Data engineer intern''',\n",
    "      \"job_title\": \"Data engineer intern\",  \n",
    "    },\n",
    "    {\n",
    "      \"company_name\": \"Orange Telecommunication Company\",\n",
    "      \"start_date\": \"Nov 22\",\n",
    "      \"end_date\": \"Jan 23\",\n",
    "      \"description\": '''Call center agent at Orange, help customers and handle angry customers''',\n",
    "      \"job_title\": \"Call center agent\",\n",
    "    },\n",
    "    {\n",
    "      \"company_name\": \"ACM\",\n",
    "      \"start_date\": \"Aug 18\",\n",
    "      \"end_date\": \"Aug 22\",\n",
    "      \"description\": '''Member at ACM, a community which solve problems through programming''',\n",
    "      \"job_title\": \"Member\",\n",
    "    },\n",
    "    {\n",
    "      \"company_name\": \"Scout group\",\n",
    "      \"start_date\": \"Aug 12\",\n",
    "      \"end_date\": \"Aug 22\",\n",
    "      \"description\": '''Leader at the scout group''',\n",
    "      \"job_title\": \"Leader\",\n",
    "    }\n",
    "  ]\n",
    "\n",
    "education = [\n",
    "    {\n",
    "      \"degree\": \"MEng in AI and data science\",\n",
    "      \"school_name\": \"Ottawa University\",\n",
    "      \"field\": \"Faculty of Engineering\",\n",
    "      \"grade\": \"\"\n",
    "    },\n",
    "    {\n",
    "      \"degree\": \"Bachelor's degree in bioinformatics\",\n",
    "      \"school_name\": \"Assiut University\",\n",
    "      \"field\": \"Faculty of Computers and Information\",\n",
    "      \"grade\": \"3.48\"\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3341aee1-d840-46c0-9515-3d81114b96a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"skills\": {\n",
      "    \"Python\": 5,\n",
      "    \"SQL\": 4,\n",
      "    \"Data Structure\": 4,\n",
      "    \"Relational DB\": 4,\n",
      "    \"Problem solving\": 4,\n",
      "    \"Data Analysis\": 5,\n",
      "    \"Artificial Intelligence\": 5,\n",
      "    \"Machine Learning\": 5,\n",
      "    \"Deep Learning\": 5,\n",
      "    \"Natural Language Processing\": 5,\n",
      "    \"Computer Vision\": 5,\n",
      "    \"Statistics\": 4,\n",
      "    \"Time Series\": 4,\n",
      "    \"Git\": 4,\n",
      "    \"GitHub\": 4,\n",
      "    \"Tableau\": 2,\n",
      "    \"Dataiku\": 2,\n",
      "    \"HPE Data fabric\": 2,\n",
      "    \"C++\": 3,\n",
      "    \"Java\": 3,\n",
      "    \"C#\": 3,\n",
      "    \"Ontology\": 3,\n",
      "    \"Genetic database pairwise sequence alignment\": 3\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "weight_profile = '''You are an expert in analyzing candidate CVs to assess skill proficiency. Given a CV, a list of extracted skills, Education as an array of dictionaries, and\n",
    "Experiences as an array of dictionaries, evaluate the candidate’s experience in each skill and assign a rating from 1 (poor) to 5 (excellent) based on:\n",
    "- Years of experience\n",
    "- Projects or work history related to the skill\n",
    "- Certifications, courses, or achievements\n",
    "\n",
    "Return the result in the following **JSON format**:\n",
    "\n",
    "{\n",
    "  \"skills\": {\n",
    "    \"Skill 1\": rate,\n",
    "    \"Skill 2\": rate\n",
    "  }\n",
    "}\n",
    "\n",
    "**Rules:**\n",
    "- If the candidate has no mention of experience for a skill, rate it 1.\n",
    "- If the skill is mentioned briefly or in a general context, rate it 2-3.\n",
    "- If the candidate has mid-experience, projects, rate it 4.\n",
    "- If the candidate has strong experience, projects, and certifications, rate it 5.\n",
    "- Write the JSON format without 'JSON' in the beginning.\n",
    "- Look up the candidate's projects from the CV.\n",
    "- Look up the experience and education from both CV and the given list.\n",
    "- If the same experience/education is present in the CV and the list, consider only the one in the CV.\n",
    "- The output should be the JSON format only.\n",
    "\n",
    "**Example Input:**\n",
    "---\n",
    "CV:\n",
    "\"Assiut University, Faculty of Computers and Information, Egypt Aug 18 – Aug 22\n",
    "Bachelor's degree in bioinformatics.Overall Grade: 3.48 out of 4.0.\n",
    "I have worked as a Data Scientist at Microsoft for 5 years, primarily using Python and TensorFlow for Machine Learning. I also have experience with SQL databases and AWS cloud services. Recently, I completed a certification in NLP.\"\n",
    "\n",
    "Extracted Skills:\n",
    "[\"Python\", \"Machine Learning\", \"SQL\", \"AWS\", \"NLP\", \"Deep Learning\"]\n",
    "\n",
    "Extracted Experience:\n",
    "[{\"company_name\": \"Microsoft\",\n",
    "\"start_date\": \"2020\",\n",
    "\"end_date\": \"2025\",\n",
    "\"description\": \"I have been working as a Data Scientist in Microsoft for 5 years, primarily using Python and TensorFlow for Machine Learning.\",\n",
    "\"job_title\": \"Data Scientist\"}]\n",
    "\n",
    "Extracted Education:\n",
    "[{\"school_name\": \"Assiut University\",\n",
    "\"field\": \"Faculty of Computers and Information\",\n",
    "\"degree\": \"Bachelor's degree in bioinformatics\",\n",
    "\"grade\": \"3.48\"}]\n",
    "\n",
    "**Expected Output:**\n",
    "---\n",
    "{\n",
    "  \"skills\": {\n",
    "    \"Python\": 5,\n",
    "    \"Machine Learning\": 5,\n",
    "    \"SQL\": 4,\n",
    "    \"AWS\": 4,\n",
    "    \"NLP\": 5,\n",
    "    \"Deep Learning\": 2\n",
    "  }\n",
    "}\n",
    "\n",
    "Now, analyze the following CV and extracted skills and return the JSON response.\n",
    "\n",
    "CV: \\n''' + pdf_text + '''\\n \\n Extracted Skills: \\n''' + f'''{CV_dict[\"skills\"]}''' + '''\\n \\n Extracted Experience: \\n''' + f'''{workExperience}''' + '''\\n \\n Extracted Education: \\n''' + f'''{education}'''\n",
    "\n",
    "profile_weight_query = client.chat.completions.create(\n",
    "\n",
    "    messages=[\n",
    "\n",
    "        {\n",
    "\n",
    "            \"role\": \"user\",\n",
    "\n",
    "            \"content\": weight_profile,\n",
    "\n",
    "        }\n",
    "\n",
    "    ],\n",
    "\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "\n",
    ")\n",
    "\n",
    "print(profile_weight_query.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79801abe-b0c7-416b-98aa-517a2a1a8696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"skills\": {\n",
      "    \"Nodejs\": 5,\n",
      "    \"Expressjs\": 5,\n",
      "    \"Django\": 4,\n",
      "    \"MongoDB\": 5,\n",
      "    \"Mongoose\": 5,\n",
      "    \"Docker\": 2,\n",
      "    \"Kafka\": 3,\n",
      "    \"NestJS\": 2,\n",
      "    \"Flask\": 2,\n",
      "    \"Sequelize\": 2,\n",
      "    \"Nginx\": 3,\n",
      "    \"Data Structures\": 4,\n",
      "    \"OOP\": 4,\n",
      "    \"Relational Database\": 4,\n",
      "    \"RESTful APIs\": 5,\n",
      "    \"OS\": 2,\n",
      "    \"Network\": 2,\n",
      "    \"Load Balancing\": 3,\n",
      "    \"NoSQL Database\": 2,\n",
      "    \"Design Patterns\": 2,\n",
      "    \"C++\": 4,\n",
      "    \"SQL\": 4,\n",
      "    \"JS\": 5,\n",
      "    \"Python\": 2,\n",
      "    \"Java\": 1,\n",
      "    \"Scala\": 1,\n",
      "    \"HTML\": 1,\n",
      "    \"Algorithmic Problem-Solving\": 4\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "weight_cv = '''You are an expert in analyzing candidate CVs to assess skill proficiency. Given a CV and a list of extracted skills, evaluate the candidate’s experience in each skill and assign a rating from 1 (poor) to 5 (excellent) based on:\n",
    "- Years of experience\n",
    "- Projects or work history related to the skill\n",
    "- Certifications, courses, or achievements\n",
    "\n",
    "Return the result in the following **JSON format**:\n",
    "\n",
    "{\n",
    "  \"skills\": {\n",
    "    \"Skill 1\": rate,\n",
    "    \"Skill 2\": rate\n",
    "  }\n",
    "}\n",
    "\n",
    "**Rules:**\n",
    "- If the candidate has **no mention** of experience for a skill, rate it **1**.\n",
    "- If the skill is mentioned **briefly** or in a general context, rate it **2-3**.\n",
    "- If the candidate has **mid experience, projects**, rate it **4**.\n",
    "- If the candidate has **strong experience, projects, or certifications**, rate it **5**.\n",
    "- Write the JSON format without 'JSON' in the beginning.\n",
    "\n",
    "**Example Input:**\n",
    "---\n",
    "CV:\n",
    "\"I have been working as a Data Scientist for 5 years, primarily using Python and TensorFlow for Machine Learning. I also have experience with SQL databases and AWS cloud services. Recently, I completed a certification in NLP.\"\n",
    "\n",
    "Extracted Skills:\n",
    "[\"Python\", \"Machine Learning\", \"SQL\", \"AWS\", \"NLP\", \"Deep Learning\"]\n",
    "\n",
    "**Expected Output:**\n",
    "---\n",
    "{\n",
    "  \"skills\": {\n",
    "    \"Python\": 5,\n",
    "    \"Machine Learning\": 5,\n",
    "    \"SQL\": 4,\n",
    "    \"AWS\": 4,\n",
    "    \"NLP\": 5,\n",
    "    \"Deep Learning\": 2\n",
    "  }\n",
    "}\n",
    "\n",
    "Now, analyze the following CV and extracted skills and return the JSON response.\n",
    "\n",
    "CV: \\n''' + pdf_text + '''\\n \\n Extracted Skills: \\n''' + f'''{CV_dict[\"skills\"]}'''\n",
    "\n",
    "CV_weight_query = client.chat.completions.create(\n",
    "\n",
    "    messages=[\n",
    "\n",
    "        {\n",
    "\n",
    "            \"role\": \"user\",\n",
    "\n",
    "            \"content\": weight_cv,\n",
    "\n",
    "        }\n",
    "\n",
    "    ],\n",
    "\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "\n",
    ")\n",
    "\n",
    "print(CV_weight_query.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "49720c66-72d7-4803-9de3-35437fd2d3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8058012\n"
     ]
    }
   ],
   "source": [
    "# CV_skills_embed = model.encode(CV_dict['skills'])\n",
    "# Job_skills_embed = model.encode(Job_dict['skills'])\n",
    "\n",
    "machine = {\n",
    "    \"Machine Learning\":5.0,\n",
    "    \"Python\":5.0,\n",
    "    \"TensorFlow\":5.0,\n",
    "    \"PyTorch\":5.0,\n",
    "    \"Scikit-learn\":5.0,\n",
    "    \"Data Preprocessing\":4.0,\n",
    "    \"Feature Engineering\":4.0,\n",
    "    \"Model Evaluation\":4.0,\n",
    "    \"Cloud Platforms\":4.0,\n",
    "    \"Amazon Web Services\":4.0,\n",
    "    \"Google Cloud Platform\":4.0,\n",
    "    \"Microsoft Azure\":4.0,\n",
    "    \"Artificial Intelligence\":5.0\n",
    "}\n",
    "\n",
    "back = {\n",
    "    \"Node.js\":5.0,\n",
    "    \"RESTful APIs\":5.0,\n",
    "    \"MongoDB\":5.0,\n",
    "    \"Express.js\":5.0,\n",
    "    \"Git\":5.0,\n",
    "    \"Asynchronous Programming\":4.0,\n",
    "    \"Event-Driven Architecture\":4.0,\n",
    "    \"Microservices Architecture\":3.0,\n",
    "    \"Cloud Platforms\":2.0,\n",
    "    \"Containerization\":2.0,\n",
    "    \"Kubernetes\":2.0,\n",
    "    \"AWS\":2.0,\n",
    "    \"Azure\":2.0\n",
    "    }\n",
    "\n",
    "analysis ={\n",
    "    \"SQL\":5.0,\n",
    "    \"Python\":5.0,\n",
    "    \"R\":5.0,\n",
    "    \"Tableau\":5.0,\n",
    "    \"Power BI\":5.0,\n",
    "    \"Google Looker Studio\":5.0,\n",
    "    \"Statistical Analysis\":3.0,\n",
    "    \"Machine Learning\":2.0,\n",
    "    \"AWS\":1.0,\n",
    "    \"Google Cloud\":1.0\n",
    "}\n",
    "\n",
    "accounting ={\n",
    "    \"Excel\":5.0,\n",
    "    \"Google Sheets\":5.0,\n",
    "    \"Data Visualization\":5.0,\n",
    "    \"Data Analysis\":5.0\n",
    "}\n",
    "\n",
    "skills_rating =  {\n",
    "    \"SQL\": 5,\n",
    "    \"Tableau\": 4,\n",
    "    \"Data Modeling\": 4,\n",
    "    \"Data Design\": 4,\n",
    "    \"Power BI\": 5,\n",
    "    \"DWH\": 4,\n",
    "    \"SSIS\": 4,\n",
    "    \"Power query\": 4,\n",
    "    \"Big Data\": 3,\n",
    "    \"SSAS\": 4,\n",
    "    \"Excel\": 4,\n",
    "    \"Statistics\": 3,\n",
    "    \"SSRS\": 4,\n",
    "    \"ETL\": 4,\n",
    "    \"Python\": 3,\n",
    "    \"Data Analysis\": 5,\n",
    "    \"Database Management\": 5\n",
    "  }\n",
    "\n",
    "CV_skills_embed = {skill: model.encode(skill)for skill in CV_dict['skills']}\n",
    "Job_skills_embed = {skill: model.encode(skill)for skill,weight in accounting.items()}\n",
    "\n",
    "\n",
    "def weighted_embed_vec(skill_dict, embedding):\n",
    "    total_weight = sum(skill_dict.values())\n",
    "    weighted_sum = sum(embedding[skill] * weight for skill,weight in skill_dict.items())\n",
    "    return weighted_sum/total_weight\n",
    "\n",
    "weighted_job = weighted_embed_vec(accounting, Job_skills_embed)\n",
    "weighted_CV = weighted_embed_vec(skills_rating, CV_skills_embed)\n",
    "# CV_skills_embed = np.mean(model.encode(CV_dict['skills']), axis=0)\n",
    "similarities = cosine_similarity([weighted_job], [weighted_CV])[0][0]\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c27cf424-95c0-4691-9a74-157c40bc3f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47975326]\n"
     ]
    }
   ],
   "source": [
    "embedding = model.encode([\"OOP\", \"object oriented programming\"])\n",
    "similarities = cosine_similarity([embedding[0]], [embedding[1]])[0]\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959102cd-6ad6-451a-8831-9cb8672c7e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
